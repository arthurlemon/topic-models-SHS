{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VISUALISATION DES RESULTATS POUR DTM ET DIM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **OBJECTIF GENERAL**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualiser les évolutions thématiques**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **OBJECTIFS SPECIFIQUES**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Visualiser évolution des groupes de mots au sein des différents thèmes\n",
    "- Visualiser évolution d'influence des différents thèmes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import bibliothèques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import tqdm\n",
    "import json\n",
    "from gensim import corpora,utils\n",
    "from gensim.models.wrappers.dtmmodel import DtmModel\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import numpy as np\n",
    "from scipy.stats import linregress\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0) Préparation des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fonctions de création du corpus**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupérer les articles en français, de type article et avec année de publication\n",
    "def filtre_corpus(Corpus, tokens):\n",
    "    \"\"\"Prend en paramètre le Corpus avec textes et métadonnées et retourne le Corpus filtré avec les articles en français et de type article\n",
    "    + les tokens nettoyés pour chacun d'entre eux et l'année de publication\"\"\"\n",
    "    Corpus_filtre = []\n",
    "    index_clean = 0\n",
    "    for index_document in tqdm(range(len(Corpus))) :\n",
    "    # on ne traite que les articles de type article et en français\n",
    "        if (Corpus[index_document]['metadata']['typeart'], Corpus[index_document]['metadata']['lang']) == ('article','fr') : \n",
    "            Corpus_filtre.append((Corpus[index_document]['metadata']['annee'], tokens[index_clean]))\n",
    "            index_clean +=1\n",
    "    return Corpus_filtre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tri_annee (Corpus_filtre):\n",
    "    \"\"\"On trie le corpus selon les années\n",
    "        Output : \n",
    "        - time_slices = liste où chaque élément contient le nombre d'articles par année\n",
    "        - articles_par_annee = liste où chaque élément est un tuple du type (année, [liste des tokens des articles de cette année])\"\"\"\n",
    "    time_slices = [] # chaque élément compte le nombre d'articles à chaque time step dans l'ordre croissant des années\n",
    "    articles_par_annee = {} # contient les tokens des articles pour chaque année de publication\n",
    "    for element in Corpus_filtre:\n",
    "        annee = element[0]\n",
    "        if annee in articles_par_annee : \n",
    "            articles_par_annee[annee].append(element[1])\n",
    "        else : articles_par_annee [annee] = [element[1]]\n",
    "    \n",
    "    articles_par_année_sorted = sorted(articles_par_annee.items()) # ordonnement par année\n",
    "    \n",
    "    for annee in range(len(articles_par_année_sorted)):\n",
    "        time_slices.append(len(articles_par_année_sorted[annee][1]))\n",
    "    return time_slices, articles_par_année_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DTMcorpus(corpora.textcorpus.TextCorpus):\n",
    "\n",
    "    def get_texts(self):\n",
    "        return self.input\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Préparation des données**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE POUR ETUDES INTERNATIONALES\n",
    "Corpus_AE = json.loads(open(\"Data/corpus_ae.json\", \"r\").read())\n",
    "tokens_AE= json.loads(open(\"Data/tokens_ae.json\", \"r\").read())\n",
    "Corpus_annees_AE = filtre_corpus(Corpus_AE, tokens_AE)\n",
    "time_slices_AE, articles_par_annee_AE = tri_annee(Corpus_annees_AE)\n",
    "train_texts_AE = []\n",
    "for annee in range(len(articles_par_annee_AE)):\n",
    "    train_texts_AE.append(articles_par_annee_AE[annee][1])\n",
    "\n",
    "train_texts_AE = [element for sublist in train_texts_AE for element in sublist]\n",
    "corpus_AE = DTMcorpus(train_texts_AE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE POUR ETUDES INTERNATIONALES\n",
    "Corpus_EI = json.loads(open(\"Data/corpus_ei.json\", \"r\").read())\n",
    "tokens_EI = json.loads(open(\"Data/tokens_ei.json\", \"r\").read())\n",
    "Corpus_annees_EI = filtre_corpus(Corpus_EI, tokens_EI)\n",
    "time_slices_EI, articles_par_annee_EI = tri_annee(Corpus_annees_EI)\n",
    "train_texts_EI = []\n",
    "for annee in range(len(articles_par_annee_EI)):\n",
    "    train_texts_EI.append(articles_par_annee_EI[annee][1])\n",
    "    \n",
    "train_texts_EI = [element for sublist in train_texts_EI for element in sublist]\n",
    "corpus_EI = DTMcorpus(train_texts_EI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE POUR RELATIONS INDUSTRIELLES\n",
    "Corpus_RI = json.loads(open(\"Data/corpus_ri.json\", \"r\").read())\n",
    "tokens_RI = json.loads(open(\"Data/tokens_ri.json\", \"r\").read())\n",
    "Corpus_annees_RI = filtre_corpus(Corpus_RI, tokens_RI)\n",
    "time_slices_RI, articles_par_annee_RI = tri_annee(Corpus_annees_RI)\n",
    "train_texts_RI = []\n",
    "for annee in range(len(articles_par_annee_RI)):\n",
    "    train_texts_RI.append(articles_par_annee_RI[annee][1])\n",
    "    \n",
    "train_texts_RI = [element for sublist in train_texts_RI for element in sublist]\n",
    "corpus_RI = DTMcorpus(train_texts_RI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Récupération des modèles**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DTM\n",
    "dtm_ae_10 = DtmModel.load('Résultats_DTM-DIM/dtm/dtm_ae_10')\n",
    "dtm_ei_10 = DtmModel.load('Résultats_DTM-DIM/dtm/dtm_ei_10')\n",
    "dtm_ri_10 = DtmModel.load('Résultats_DTM-DIM/dtm/dtm_ri_10')\n",
    "\n",
    "# DIM\n",
    "dim_ae_10 = DtmModel.load('Résultats_DTM-DIM/dim/dim_ae_10')\n",
    "dim_ei_10 = DtmModel.load('Résultats_DTM-DIM/dim/dim_ei_10')\n",
    "dim_ri_10 = DtmModel.load('Résultats_DTM-DIM/dim/dim_ri_10')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) PyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis\n",
    "pyLDAvis.enable_notebook()\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BUG** : temps de run très long (>15min ?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_topic, topic_term, doc_lengths, term_frequency, vocab = dtm_ae_10.dtm_vis(time=0, corpus=corpus_AE)\n",
    "vis_wrapper = pyLDAvis.prepare(topic_term_dists=topic_term, doc_topic_dists=doc_topic, doc_lengths=doc_lengths, vocab=vocab, term_frequency=term_frequency)\n",
    "pyLDAvis.show(vis_wrapper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2)  STATISTIQUES DE TOPIC MODELING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Probabilité d'une paire mot/thème**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Définition : force d'un mot au sein d'un thème donné. Autrement dit, on mesure la probabilité d'un mot sachant un thème donné. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def term_distribution(model, term, topic):\n",
    "    \"\"\"Probabilité à chaque année d'une paire mot/thème\"\"\"\n",
    "    word_index = model.id2word.token2id[term]\n",
    "    topic_slice = np.exp(model.lambda_[topic])\n",
    "    topic_slice = topic_slice / topic_slice.sum(axis=0)\n",
    "    return topic_slice[word_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple\n",
    "term_distribution(dtm_ae_10, term='économie', topic=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mesure de variance pour un token**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Définition : indique la variance en probabilité des mots d'un thème au cours du temps. Autrement dit, les mots dont l'importance relative changent le plus au cours du temps pour un thème donné sont les plus porteurs d'information relative au changement de thème."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def term_variance(model, topic):\n",
    "    \"\"\"Donne la variance dans le temps de mots pour un thème donné\n",
    "       Plus la variance est élevée, plus le mot est d'intérêt\"\"\"\n",
    "    p = np.exp(model.lambda_[topic]) /\\\n",
    "        np.exp(model.lambda_[topic]).sum(axis=0)\n",
    "    variances = np.var(p, axis=1)\n",
    "    order = np.argsort(variances)[::-1]\n",
    "    terms = np.array([term for term, _\n",
    "                    in sorted(model.id2word.token2id.items(),\n",
    "                              key=lambda x: x[1])])[order]\n",
    "    variances = variances[order]\n",
    "    return list(zip(terms, variances))[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple\n",
    "term_variance(dtm_ae_10, topic=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pente de variation en probabilité d'un mot au sein d'un thème**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " def term_slope(model, topic):\n",
    "        \"\"\"Mesure d'une pente de variation dans le temps pour les mots composant un thème\n",
    "        Peut s'interpréter comme une mesure de popularité dans le temps\"\"\"\n",
    "        p = np.exp(model.lambda_[topic]) /\\\n",
    "            np.exp(model.lambda_[topic]).sum(axis=0)\n",
    "        slopes = np.apply_along_axis(\n",
    "            lambda y: linregress(x=range(len(y)), y=y).slope, axis=1, arr=p)\n",
    "        order = np.argsort(slopes)\n",
    "        terms = np.array([term for term, _\n",
    "                        in sorted(model.id2word.token2id.items(),\n",
    "                                    key=lambda x: x[1])])[order]\n",
    "        slopes = slopes[order]\n",
    "        return list(zip(terms, slopes))[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_slope(dtm_ae_10, topic=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Plots temporels par mot et thème"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def term_distribution(model, term, topic):\n",
    "    \"\"\"Probabilité à chaque année d'une paire mot/thème\"\"\"\n",
    "    word_index = model.id2word.token2id[term]\n",
    "    topic_slice = np.exp(model.lambda_[topic])\n",
    "    topic_slice = topic_slice / topic_slice.sum(axis=0)\n",
    "    return topic_slice[word_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_slices_labels_AE = [element[0] for element in articles_par_annee_AE]\n",
    "time_slices_labels_EI = [element[0] for element in articles_par_annee_EI]\n",
    "time_slices_labels_RI = [element[0] for element in articles_par_annee_RI]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_terms( model, topic, time, time_slice_labels, num_words=5, revue = 'AE', title=None, name=None, hide_y=False, plot=False):\n",
    "        \"\"\"Creates a plot of term probabilities over time in a given topic.\"\"\"\n",
    "        \n",
    "        terms = [element[1] for element in model.show_topic(topicid=topic, time=time, num_words=num_words)]\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(15,5))\n",
    "        #plt.style.use('fivethirtyeight')\n",
    "        for term in terms:\n",
    "            try:\n",
    "                ax.plot(\n",
    "                    time_slice_labels, term_distribution(model,term, topic),\n",
    "                    label=term)\n",
    "            except KeyError as e : print(repr(e), \" --- Le mot \", term, \"n'est pas dans le vocabulaire du corpus\")\n",
    "        leg = ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "        plt.xticks(rotation=90)\n",
    "        if hide_y:\n",
    "            ax.set_yticklabels([])\n",
    "        ax.set_ylabel('Probability')\n",
    "        if title:\n",
    "            ax.set_title('Evolution des '+ str(num_words) + ' tokens majoritaires en ' + str(time_slice_labels[time]) + ' pour le thème ' +  str(topicid))\n",
    "        if name:\n",
    "            fig.savefig('Plots/DTM/'+ revue +\n",
    "                '/plot_dtm_topic=' + str(topic) + '_time=' + str(time_slice_labels[time]), dpi=300, bbox_extra_artists=(leg,), bbox_inches='tight')\n",
    "        if not plot:\n",
    "            plt.close()\n",
    "        else :\n",
    "            return fig, ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plots pours AE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_ids = [x for x in range(10)][5:]\n",
    "time_slices, time_slices_labels = time_slices_AE, time_slices_labels_AE\n",
    "times = [x for x in range(len(time_slices_labels))]\n",
    "\n",
    "# On considère les mots prédominants lors d'une année avec un intervalle de 10 ans entre chaque année\n",
    "selected_time_slices = [x for x in range(0, len(time_slices), 10)]\n",
    "for topicid in tqdm(topics_ids):\n",
    "    for time in selected_time_slices:\n",
    "        plot_terms(model=dtm_ae_10, topic=topicid, time = time, time_slice_labels=time_slices_labels_AE, topn=5, title='Evolution des 5 tokens majoritaires', name=True, plot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plots pours EI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_ids = [x for x in range(10)]\n",
    "time_slices, time_slices_labels = time_slices_EI, time_slices_labels_EI\n",
    "times = [x for x in range(len(time_slices_labels))]\n",
    "\n",
    "# On considère les mots prédominants lors d'une année avec un intervalle de 10 ans entre chaque année\n",
    "selected_time_slices = [x for x in range(0, len(time_slices), 10)]\n",
    "for topicid in tqdm(topics_ids):\n",
    "    for time in selected_time_slices:\n",
    "        plot_terms(model=dtm_ei_10, topic=topicid, time = time, time_slice_labels=time_slices_labels, num_words=5, revue='EI', title='Evolution des 5 tokens majoritaires', name=True, plot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plots pours RI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics_ids = [x for x in range(10)][6:]\n",
    "time_slices, time_slices_labels = time_slices_RI, time_slices_labels_RI\n",
    "times = [x for x in range(len(time_slices_labels))]\n",
    "\n",
    "# On considère les mots prédominants lors d'une année avec un intervalle de 10 ans entre chaque année\n",
    "selected_time_slices = [x for x in range(0, len(time_slices), 10)]\n",
    "for topicid in tqdm(topics_ids):\n",
    "    for time in selected_time_slices:\n",
    "        plot_terms(model=dtm_ri_10, topic=topicid, time = time, time_slice_labels=time_slices_labels, num_words=5, revue='RI', title='Evolution des 5 tokens majoritaires', name=True, plot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupérer les mots les plus significatifs à un instant t\n",
    "time = 0\n",
    "topicid = 9\n",
    "time_slices_labels_AE[time]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Moyenne des tokens sur toute la période de publication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens_by_topics (model = dtm_ae_10, time_slices= time_slices_AE):\n",
    "    tokens_by_topics = dict.fromkeys((x for x in range(10)),{})\n",
    "    for topic in tqdm(range(10)):\n",
    "        tokens={}\n",
    "        for time in range(len(time_slices)):\n",
    "            for element in model.show_topic(topicid=topic,time=time):\n",
    "                if element[1] in tokens:\n",
    "                    tokens[element[1]] += element[0]\n",
    "                else : \n",
    "                    tokens[element[1]] = element[0]\n",
    "        tokens = {k: v /len(time_slices)  for k, v in tokens.items()}\n",
    "        tokens_by_topics[topic] = tokens\n",
    "    return tokens_by_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print pour stocker dans excel\n",
    "def print_tokens_by_topics(tokens_by_topics):\n",
    "    for topic in range(10):\n",
    "        print('Topic ' + str(topic))\n",
    "        d = sorted(tokens_by_topics[topic].items(), key=lambda x: x[1], reverse=True)\n",
    "        i=0\n",
    "        for element in d:\n",
    "            while i < 10:\n",
    "                print(d[i][0])\n",
    "                i+=1\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_by_topics_AE = tokens_by_topics(dim_ae_10, time_slices_AE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_tokens_by_topics(tokens_by_topics=tokens_by_topics_AE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_by_topics_EI = tokens_by_topics(dim_ei_10, time_slices_EI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_tokens_by_topics(tokens_by_topics=tokens_by_topics_EI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_by_topics_RI = tokens_by_topics(dim_ri_10, time_slices_RI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_tokens_by_topics(tokens_by_topics=tokens_by_topics_RI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tableau avec les n termes plus représentatif d'un thème en fonction du temps**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_slices_labels_AE = [element[0] for element in articles_par_annee_AE]\n",
    "time_slices_labels_EI = [element[0] for element in articles_par_annee_EI]\n",
    "time_slices_labels_RI = [element[0] for element in articles_par_annee_RI]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_term_table(model, topic, slices, time_slice_label, topn=30, print_=True):\n",
    "    \"\"\"Returns a dataframe with the top n terms in the topic for each of\n",
    "    the given time slices.\"\"\"\n",
    "    data = {}\n",
    "    for time_slice in slices:\n",
    "        time = time_slice_label.index(str(time_slice))\n",
    "        data[time_slice] = [\n",
    "            term for p, term\n",
    "            in model.show_topic(topic, time=time, topn=topn)\n",
    "        ]\n",
    "    if print_:\n",
    "        print(pd.DataFrame(data))\n",
    "        \n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slices = [1960,1970,1980, 1990, 2000,2010]\n",
    "for topic in range(10):\n",
    "    # DTM\n",
    "    top_table_ae_topic = top_term_table(dtm_ae_10, topic=topic,slices=slices,time_slice_label= time_slices_labels_AE)\n",
    "    top_table_ae_topic.to_pickle('Plots/DTM/AE/Tables Top Mots par an/top_terms_topic='+str(topic))\n",
    "    # DIM \n",
    "    top_table_ae_topic = top_term_table(dim_ae_10, topic=topic,slices=slices,time_slice_label= time_slices_labels_AE)\n",
    "    top_table_ae_topic.to_pickle('Plots/DIM/AE/Tables Top Mots par an/top_terms_topic='+str(topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slices = [1970,1980, 1990, 2000,2010]\n",
    "for topic in range(10):\n",
    "    # DTM\n",
    "    top_table_ei_topic = top_term_table(dtm_ei_10, topic=topic,slices=slices,time_slice_label= time_slices_labels_EI)\n",
    "    top_table_ei_topic.to_pickle('Plots/DTM/EI/Tables Top Mots par an/top_terms_topic='+str(topic))\n",
    "    # DIM\n",
    "    top_table_ei_topic = top_term_table(dim_ei_10, topic=topic,slices=slices,time_slice_label= time_slices_labels_EI)\n",
    "    top_table_ei_topic.to_pickle('Plots/DIM/EI/Tables Top Mots par an/top_terms_topic='+str(topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slices = [1950,1960, 1970,1980, 1990, 2000,2010]\n",
    "for topic in range(10):\n",
    "    # DTM\n",
    "    top_table_ri_topic = top_term_table(dtm_ri_10, topic=topic,slices=slices,time_slice_label= time_slices_labels_RI)\n",
    "    top_table_ri_topic.to_pickle('Plots/DTM/RI/Tables Top Mots par an/top_terms_topic='+str(topic))\n",
    "    # DIM\n",
    "    top_table_ri_topic = top_term_table(dim_ri_10, topic=topic,slices=slices,time_slice_label= time_slices_labels_RI)\n",
    "    top_table_ri_topic.to_pickle('Plots/DIM/RI/Tables Top Mots par an/top_terms_topic='+str(topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_table_ri_topic = top_term_table(dim_ri_10, topic=topic,slices=slices,time_slice_label= time_slices_labels_RI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Récupération des tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    df = pd.read_pickle('Plots/DIM/AE/Tables Top Mots par an/top_terms_topic=' +str(i))\n",
    "    print(\"Thème \", str(i) + \"\\n\",  df,\"\\n\", \"-\"*40 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Résumé pour tous les thèmes et par année**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary(model, slices, time_slices_labels, topn=10):\n",
    "    \"\"\"Prints a summary of all the topics\"\"\"\n",
    "    for topic in range(model.num_topics):\n",
    "        print('Topic %d' % topic)\n",
    "        print(top_term_table(model, topic=topic,slices=slices,time_slice_label= time_slices_labels))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slices = [1960,1970,1980, 1990, 2000,2010]\n",
    "summary(model=dtm_ae_10,slices=slices, time_slices_labels=time_slices_labels_AE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evolution temporelle des mots-clés"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idée : étudier la répartition de certains mots-clés en fonction du temps (cf baseline pour modèle dynamique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Récupérer les métadonnées et tokens pour les articles\n",
    "def filtre_corpus_année(Corpus, tokens):\n",
    "    \"\"\"Prend en paramètre le Corpus avec textes et métadonnées et retourne le Corpus filtré avec les articles en français et de type article\n",
    "    + les tokens nettoyés pour chacun d'entre eux\"\"\"\n",
    "    Corpus_filtre = []\n",
    "    index_clean = 0\n",
    "    for index_document in tqdm_notebook(range(len(Corpus))) :\n",
    "    # on ne traite que les articles de type article et en français\n",
    "        if (Corpus[index_document]['metadata']['typeart'], Corpus[index_document]['metadata']['lang']) == ('article','fr') : \n",
    "            Corpus_filtre.append((Corpus[index_document]['URL'], Corpus[index_document]['metadata']['title'], \n",
    "                                  Corpus[index_document]['metadata']['annee'], tokens[index_clean]))\n",
    "            index_clean +=1\n",
    "    return Corpus_filtre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r Corpus_EI\n",
    "%store -r tokens_bigrams_Corpus_LDA_EI_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Corpus_EI_LDA_metadata_annee = filtre_corpus_année(Corpus_EI, tokens_bigrams_Corpus_LDA_EI_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compte_frequence_EI contient pour chaque article un quadruplet de la forme : (URL, titre, annee, (token , occurence du token))\n",
    "compte_frequence_EI_annee = []\n",
    "for article in Corpus_EI_LDA_metadata_annee:\n",
    "    compte_frequence_EI_annee.append((article[0], article[1], article[2], compte_frequences(article[3])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_string_annee(string, string2 ='', double_check=False):\n",
    "    \"\"\"Chercher un token d'intérêt et retourner le quadruplet de compte_frequence_AE le cas échéant\"\"\"\n",
    "    articles_par_années ={}\n",
    "    articles_with_string = []\n",
    "    for article in compte_frequence_EI_annee:\n",
    "        for element in article[3]:\n",
    "            if string == element[0]:\n",
    "                if double_check == True: #option pour vérifier la présence simultanée de 2 string dans le même texte\n",
    "                    for element in article[3] :\n",
    "                        if string2 == element[0]:\n",
    "                            try: articles_par_années[article[2]].appendl(article)\n",
    "                            except: articles_par_années[article[2]] = [article]\n",
    "                            break\n",
    "                else : \n",
    "                    try: articles_par_années[article[2]].append(article)\n",
    "                    except: articles_par_années[article[2]] = [article]\n",
    "                    break\n",
    "    return articles_par_années"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_repartition_mot(test_string):\n",
    "    annees = sorted([annee for annee in test_string])\n",
    "    comptes = [len(test_string[annee]) for annee in annees]\n",
    "    fig = plt.figure(figsize=(10,8))\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.bar(annees,comptes)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_string = find_string_annee('identité', '', double_check=False)\n",
    "plot_repartition_mot(test_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "slices = [1960,1970,1980, 1990, 2000,2010]\n",
    "summary(model=model,slices=slices, time_slices_labels=time_slices_labels_AE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DIM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'influence est une fonction avec 3 variables :\n",
    "- article\n",
    "- thème\n",
    "- année"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_slices_labels_AE = [element[0] for element in articles_par_annee_AE]\n",
    "time_slices_labels_EI = [element[0] for element in articles_par_annee_EI]\n",
    "time_slices_labels_RI = [element[0] for element in articles_par_annee_RI]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_term_table(model, topic, slices, time_slice_label, topn=10):\n",
    "    \"\"\"Returns a dataframe with the top n terms in the topic for each of\n",
    "    the given time slices.\"\"\"\n",
    "    data = {}\n",
    "    for time_slice in slices:\n",
    "        time = time_slice_label.index(str(time_slice))\n",
    "        data[time_slice] = [\n",
    "            term for p, term\n",
    "            in model.show_topic(topic, time=time, topn=topn)\n",
    "        ]\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupérer les articles en français, de type article et avec année de publication\n",
    "def filtre_corpus_metadata(Corpus, tokens, time_slices_labels = time_slices_labels_AE):\n",
    "    \"\"\"Prend en paramètre le Corpus avec textes et métadonnées et retourne le Corpus filtré avec les articles en français et de type article\n",
    "    + les tokens nettoyés pour chacun d'entre eux et l'année de publication\"\"\"\n",
    "    Corpus_filtre = dict.fromkeys(time_slices_labels)\n",
    "    index_clean = 0\n",
    "    for index_document in tqdm(range(len(Corpus))) :\n",
    "    # on ne traite que les articles de type article et en français\n",
    "        if (Corpus[index_document]['metadata']['typeart'], Corpus[index_document]['metadata']['lang']) == ('article','fr') : \n",
    "            try :\n",
    "                Corpus_filtre[Corpus[index_document]['metadata']['annee']].append((Corpus[index_document]['URL'], Corpus[index_document]['metadata']['title'],tokens[index_clean])) \n",
    "            except:\n",
    "                Corpus_filtre[Corpus[index_document]['metadata']['annee']] =[(Corpus[index_document]['URL'], Corpus[index_document]['metadata']['title'],tokens[index_clean])]\n",
    "            index_clean +=1\n",
    "    return Corpus_filtre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_documents_influents_par_année (topic=0, time_slices=time_slices_AE, articles_par_annee = articles_par_annee_AE, time_slices_labels = time_slices_labels_AE):\n",
    "    \"\"\"Pour un thème donné, retourne un dictionnaire du type (année, (influence, tokens du documents)) trié par ordre décroissant d'influence à chaque année\"\"\"\n",
    "    \n",
    "    # Récupération des valeurs d'influence pour les articles à chaque temps t\n",
    "    influents_par_année = []\n",
    "    for time_slice in range(len(time_slices)): # chaque année\n",
    "        document_influent =[]\n",
    "        for document in range(time_slices[time_slice]): # chaque document publié cette année-là\n",
    "            document_influent.append(model.influences_time[time_slice][document][topic])\n",
    "        influents_par_année.append(document_influent)\n",
    "        \n",
    "    # Lien entre influence et liste de tokens de l'article\n",
    "    dico_influences = {}\n",
    "    for time_slice in range(len(time_slices_AE)):\n",
    "        dico = []\n",
    "        for index in range(len(articles_par_annee[time_slice][1])):\n",
    "            dico.append((influents_par_année[time_slice][index],articles_par_annee[time_slice][1][index]))\n",
    "        dico_influences[time_slices_labels[time_slice]] = dico\n",
    "        \n",
    "    # tri par ordre décroissant d'influence à chaque année\n",
    "    for key, value in dico_influences.items(): \n",
    "        value.sort(key=lambda tup: tup[0], reverse=True)\n",
    "        \n",
    "    return dico_influences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_influence_metadata (dico_influences, corpus_metadata, time_slices_labels = time_slices_labels_AE):\n",
    "    \"\"\"Associer influence avec métadonnées de l'article\n",
    "    Output : dico du type (année : [[influence, (URL, titre, tokens)], ...])\"\"\"\n",
    "    dico_influence_metadata = dict.fromkeys(time_slices_labels)\n",
    "    for année, liste in corpus_metadata.items():\n",
    "        for element in liste :\n",
    "            for element_2 in dico_influences[année]:\n",
    "                if element[2] == element_2[1]:\n",
    "                    try : \n",
    "                        dico_influence_metadata[année].append((element_2[0], element))\n",
    "                    except :\n",
    "                        dico_influence_metadata[année] = [(element_2[0], element)]\n",
    "    \n",
    "    # tri par ordre décroissant d'influence à chaque année\n",
    "    for key, value in dico_influence_metadata.items(): \n",
    "        value.sort(key=lambda tup: tup[0], reverse=True)\n",
    "        \n",
    "    return dico_influence_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DtmModel.load('Résultats_DTM-DIM/dim/dim_ae_10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Préparation du corpus\n",
    "corpus_ae_metadata = filtre_corpus_metadata(Corpus_AE,tokens_AE, time_slices_labels_AE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**VISUALISATION DES DOCUMENTS INFLUENTS par rapport aux documents où le THEME est prédominant**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_et_influents(model, dico_influence_metadata, slices, time_slices_labels, topn=10, topic=0):\n",
    "    \"\"\"Affiche les mots clés prédominants pour un thème et les documents influents à chaque temps t\"\"\"\n",
    "    print('Topic %d' % topic)\n",
    "    print(top_term_table(model, topic=topic,slices=slices,time_slice_label= time_slices_labels))\n",
    "    print()\n",
    "    for année in slices:\n",
    "        print('Documents les plus influents en', str(année))\n",
    "        for element in dico_influence_metadata[str(année)][:5]:\n",
    "            print(element[1][1])\n",
    "    \n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for element in dico_influence_metadata_ae['1980']:\n",
    "    print(element[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic=2\n",
    "dico_influences_AE = get_documents_influents_par_année(topic=topic, time_slices=time_slices_AE, articles_par_annee = articles_par_annee_AE, time_slices_labels = time_slices_labels_AE)\n",
    "dico_influence_metadata_ae = get_influence_metadata(time_slices_labels = time_slices_labels_AE, dico_influences = dico_influences_AE, corpus_metadata = corpus_ae_metadata)\n",
    "summary_et_influents(model=model, slices = [1960,1970,1980, 1990, 2000,2010], time_slices_labels=time_slices_labels_AE, topic=topic, dico_influence_metadata = dico_influence_metadata_ae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic=1\n",
    "dico_influences_AE = get_documents_influents_par_année(topic=topic, time_slices=time_slices_AE, articles_par_annee = articles_par_annee_AE, time_slices_labels = time_slices_labels_AE)\n",
    "dico_influence_metadata_ae = get_influence_metadata(time_slices_labels = time_slices_labels_AE, dico_influences = dico_influences_AE, corpus_metadata = corpus_ae_metadata)\n",
    "summary_et_influents(model, slices = [1960,1970,1980, 1990, 2000,2010], time_slices_labels=time_slices_labels_AE, topic=topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic=3\n",
    "dico_influences_AE = get_documents_influents_par_année(topic=topic, time_slices=time_slices_AE, articles_par_annee = articles_par_annee_AE, time_slices_labels = time_slices_labels_AE)\n",
    "dico_influence_metadata_ae = get_influence_metadata(time_slices_labels = time_slices_labels_AE, dico_influences = dico_influences_AE, corpus_metadata = corpus_ae_metadata)\n",
    "summary_et_influents(model, slices = [1960,1970,1980, 1990, 2000,2010], time_slices_labels=time_slices_labels_AE, topic=topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot temporel de l'influence globale d'un thème**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checker le document le plus influent au temps t=time pour chaque topic\n",
    "def create_dico_topic(model, time_slices):\n",
    "    dico_topic = {}\n",
    "    for topic in range(model.num_topics):\n",
    "        dico_topic[topic] = []\n",
    "        for time in range(len(time_slices)):\n",
    "            influence_time = 0\n",
    "            for document in range(time_slices[time]):\n",
    "                # on somme les influences des différents documents de cette slice\n",
    "                influence_time +=  model.influences_time[time][document][topic]\n",
    "            # normalisation par le nombre de documents à ce temps t\n",
    "            dico_topic[topic].append(influence_time/time_slices[time])\n",
    "    return dico_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_topics_trend(topics, dico_topic, time_slice_labels, revue = 'AE', title=None, name=None, plot=True):\n",
    "        \"\"\"Trace l'évolution de l'influence des thèmes\"\"\"        \n",
    "        fig, ax = plt.subplots(figsize=(15,5))\n",
    "        for topic in topics:\n",
    "            ax.plot(time_slice_labels, dico_topic[topic], label=topic)\n",
    "        \n",
    "        leg = ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "        plt.xticks(rotation=90)\n",
    "        \n",
    "        ax.set_ylabel('Influence')\n",
    "        if title:\n",
    "            ax.set_title('Evolution de l\\'influence des thèmes pour le modèle LDA à 10 thèmes sur la revue '+ revue)\n",
    "        if name:\n",
    "            fig.savefig('Plots/DIM/'+ revue +\n",
    "                '/Plots temporels/evolution_influence_thèmes_'+ revue +'_topics=' + str(topics) , dpi=300, bbox_extra_artists=(leg,), bbox_inches='tight')\n",
    "        if not plot:\n",
    "            plt.close()\n",
    "        else :\n",
    "            return fig, ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico_topic_AE = create_dico_topic(model=dim_ae_10, time_slices=time_slices_AE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_topics_trend(topics=[x for x in range(10)], dico_topic=dico_topic_AE, time_slice_labels=time_slices_labels_AE, revue = 'AE', title=True, name=True, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_topics_trend(topics=[2,4], time_slice_labels=time_slices_labels_AE, revue = 'AE', title=True, name=True, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_topics_trend(topics=[0], time_slice_labels=time_slices_labels_AE, revue = 'AE', title=True, name=True, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_ae_10.show_topic(topicid=2,time=30,topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_topics_trend(topics=[3,5,6,7,8,9],dico_topic=dico_topic_AE, time_slice_labels=time_slices_labels_AE, revue = 'AE', title=True, name=True, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_ae_10.show_topic(topicid=3,time=30,topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_ae_10.show_topic(topicid=5,time=30,topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_ae_10.show_topic(topicid=6,time=60,topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico_topic_EI = create_dico_topic(model=dim_ei_10, time_slices=time_slices_EI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_topics_trend(topics=[x for x in range(10)], dico_topic=dico_topic_EI, time_slice_labels=time_slices_labels_EI, revue = 'EI', title=True, name=True, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_topics_trend(topics=[4,9], dico_topic=dico_topic_EI, time_slice_labels=time_slices_labels_EI, revue = 'EI', title=True, name=None, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_ei_10.show_topic(topicid=4,time=30,topn=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_ei_10.show_topic(topicid=9,time=40,topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dico_topic_RI = create_dico_topic(model=dim_ri_10, time_slices=time_slices_RI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_topics_trend(topics=[x for x in range(10)], dico_topic=dico_topic_RI, time_slice_labels=time_slices_labels_RI, revue = 'RI', title=True, name=True, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vérifier le document le plus influent au temps t=time pour chaque topic\n",
    "time = 30\n",
    "influences = [-1 for _ in range(10)]\n",
    "documents = [0 for _ in range(10)]\n",
    "for topic in range(10):\n",
    "    for document in range(time_slices_AE[time]):\n",
    "        if dim_ae_10.influences_time[time][document][topic] > influences[topic]:\n",
    "            influences[topic] = dim_ae_10.influences_time[time][document][topic]\n",
    "            documents[topic] = document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents, influences"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
