{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VALIDATION EXTERNE DES THEMES IDENTIFIES PAR LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **OBJECTIF GENERAL**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Préparer la tâche de fouille de documents évaluée par un sondage auprès d'experts en SHS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **OBJECTIFS SPECIFIQUES**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Récupérer en ligne un champ lexical associé aux thèmes de recherche des rédacteurs des 3 revues d'étude : AE - RI - EI\n",
    "- Mesurer (distance - mots_communs) la composition des thèmes trouvés par inférence avec la composition des thèmes a priori\n",
    "- Mesurer la distance entre tous les mots d'un article identifié à un thème précis dominant et le champ lexical du thème extérieur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **METHODE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Identifier les thèmes de recherche des rédacteurs des revues (cf *Erudit - Analyse.xls*)\n",
    "- Rechercher sur https://www.rimessolides.com/motscles.aspx les champs lexicaux associés aux thèmes identifiés\n",
    "- Récupérer les tokens (unigrammes et bigrammes) dans un dictionnaire du type {'theme_a_priori' : [tokens]}\n",
    "- Filtrer avec les 30 mots les plus fréquents/sémantiquement liés dans ces tokens\n",
    "- Compter le nombre de mots communs entre chaque thème LDA et les tokens des thèmes a priori\n",
    "- En déduire un étiquettage de chaque thème si suffisamment de mots en commun (seuil ?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Construction d'une tâche d'évaluation : fouille de documents parmi chaque revue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import bibliothèques**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import load_workbook\n",
    "\n",
    "from gensim.models import LdaModel\n",
    "from gensim import models, similarities\n",
    "import gensim\n",
    "\n",
    "import pandas as pd\n",
    "import pandas as pdutifulSoup #parsing du XML\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "import urllib.request\n",
    "import requests #requête des serveurs XML\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "import collections\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) IDENTIFICATION DES THEMES DE RECHERCHE DES REVUES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output\n",
    "- thèmes_AE\n",
    "- thèmes_EI\n",
    "- thèmes_RI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = 'C:/Users/arten/OneDrive - polymtl.ca/Documents/Etudes/Montréal/Etudes/Projet de recherche/Erudit/'\n",
    "\n",
    "# Récupération du fichier excel\n",
    "wb = load_workbook(cwd +'Erudit-Analyse.xlsx')\n",
    "\n",
    "# Identification de la feuille d'intérêt\n",
    "print(wb.sheetnames)\n",
    "sheet = wb['Mots-clés']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RELATIONS INDUSTRIELLES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupération des thèmes sous forme de liste\n",
    "thèmes_RI = sheet['A2'].value.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ETUDES INTERNATIONALES**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupération des thèmes sous forme de liste\n",
    "thèmes_EI = sheet['B2'].value.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ACTUALITE ECONOMIQUE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupération des thèmes sous forme de liste\n",
    "thèmes_AE = sheet['C2'].value.split(\"\\n\")\n",
    "thèmes_AE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Résumé**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Nombre de thèmes a priori identifiés pour les revues:\\n', 'Actualité Economique :' , len(thèmes_AE), '\\n Etudes internationales :' , len(thèmes_EI),'\\n Relations Industrielles : ', len(thèmes_RI))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) REQUETE ET CONSTITUTION DES CHAMPS LEXICAUX SUR RIMES SOLIDES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Rechercher sur https://www.rimessolides.com/motscles.aspx les champs lexicaux associés aux thèmes identifiés\n",
    "- Récupérer les tokens (unigrammes et bigrammes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output\n",
    "- champ_lexical_AE\n",
    "- champ_lexical_EI\n",
    "- champ_lexical_RI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_url (liste_thèmes, url = 'https://www.rimessolides.com/motscles.aspx?m='):\n",
    "    \"\"\"Fonction qui parcoure la page web contenant le champ lexical de chaque thème et retourne une liste d'objets request\"\"\"\n",
    "    liste_r = []\n",
    "    for thème in liste_thèmes:\n",
    "        try: \n",
    "            url_path = url + thème\n",
    "            r = requests.get(url_path)\n",
    "            liste_r.append((thème,r))\n",
    "        except:\n",
    "            print('Pas d\\'url trouvé pour le thème ', thème)\n",
    "    return liste_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens(liste_r, thèmes):     \n",
    "    \"\"\"\"Fonction qui parcoure la liste d'objets request et retourne un dictionnaire du type {thème : [liste tokens]}\"\"\"\n",
    "    champ_lexical = {}\n",
    "    for thème in thèmes:\n",
    "        champ_lexical[thème] = []\n",
    "    for thème, r in liste_r:\n",
    "        soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "        for td in soup.findAll(\"table\", class_ =\"tb-motcle\"):\n",
    "            for element in td.findAll(\"a\"):\n",
    "                champ_lexical[thème].append(element.text)\n",
    "    return champ_lexical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Actualité économique**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_url_AE = parse_url(thèmes_AE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "champ_lexical_AE = get_tokens(liste_url_AE,thèmes_AE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Relations Industrielles**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_url_RI = parse_url(thèmes_RI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "champ_lexical_RI = get_tokens(liste_url_RI, thèmes_RI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Etudes Internationales**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_url_EI = parse_url(thèmes_EI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "champ_lexical_EI = get_tokens(liste_url_EI,thèmes_EI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store champ_lexical_EI\n",
    "%store champ_lexical_AE\n",
    "%store champ_lexical_RI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) MESURE DE SIMILARITE ENTRE THEME LDA ET THEME A PRIORI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Préprocessing des mots issus de rimesolides pour permettre la mesure d'edit distance/mots communs avec les thèmes du LDA\n",
    "- Comparaison entre les 2 pools de thèmes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output:\n",
    "- champ_lexical_EI_clean\n",
    "- champ_lexical_AE_clean\n",
    "- champ_lexical_RI_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r champ_lexical_EI\n",
    "%store -r champ_lexical_AE\n",
    "%store -r champ_lexical_RI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "champ_lexical_RI_clean.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préprocessing des champs lexicaux"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vérification du nombre de mots composant chaque thème (minimum 5 nécessaire)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longueur_EI = sorted([len(champ_lexical_EI[mot]) for mot in champ_lexical_EI])\n",
    "longueur_AE = sorted([len(champ_lexical_AE[mot]) for mot in champ_lexical_AE])\n",
    "longueur_RI = sorted([len(champ_lexical_RI[mot]) for mot in champ_lexical_RI])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar([i for i in range(len(longueur_AE))], longueur_AE)\n",
    "plt.axhline(y=5, color = 'red')\n",
    "plt.axhline(y=30, color = 'purple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajouter manuellement des thèmes plus larges\n",
    "add_themes = ['Économétrie', 'Économie']\n",
    "add_url_AE = parse_url(add_themes)\n",
    "add_tokens = get_tokens(add_url_AE,add_themes)\n",
    "champ_lexical_AE.update(add_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enlever les thèmes avec trop peu de mots-clés (< 10 mots)\n",
    "champ_lexical_AE = {i:champ_lexical_AE[i] for i in champ_lexical_AE if len(champ_lexical_AE[i]) > 10}\n",
    "\n",
    "# Garder uniquement les 30 premiers mots-clés de chaque thème\n",
    "restriction_tokens = {i:champ_lexical_AE[i][:30] for i in champ_lexical_AE if len(champ_lexical_AE[i]) > 30}\n",
    "\n",
    "# Constitution du champ lexical final\n",
    "champ_lexical_AE.update(restriction_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "champ_lexical_AE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar([i for i in range(len(longueur_EI))], longueur_EI)\n",
    "plt.axhline(y=5, color = 'red')\n",
    "plt.axhline(y=30, color = 'purple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([(item,len(value)) for (item,value) in champ_lexical_EI.items() if len(value) <10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "champ_lexical_EI.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajouter manuellement des thèmes plus larges\n",
    "add_themes = ['Politique de défense', 'Stratégie']\n",
    "add_url_EI = parse_url(add_themes)\n",
    "add_tokens = get_tokens(add_url_EI,add_themes)\n",
    "champ_lexical_EI.update(add_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enlever les thèmes avec trop peu de mots-clés (< 10 mots)\n",
    "champ_lexical_EI = {i:champ_lexical_EI[i] for i in champ_lexical_EI if len(champ_lexical_EI[i]) > 10}\n",
    "\n",
    "# Garder uniquement les 30 premiers mots-clés de chaque thème\n",
    "restriction_tokens = {i:champ_lexical_EI[i][:30] for i in champ_lexical_EI if len(champ_lexical_EI[i]) < 30}\n",
    "\n",
    "# Constitution du champ lexical final\n",
    "champ_lexical_EI.update(restriction_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([len(restriction_tokens[item]) for item in restriction_tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([len(champ_lexical_EI[item]) for item in champ_lexical_EI])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(champ_lexical_EI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar([i for i in range(len(longueur_RI))], longueur_RI)\n",
    "plt.axhline(y=5, color = 'red')\n",
    "plt.axhline(y=30, color = 'purple')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([(item,len(value)) for (item,value) in champ_lexical_RI.items() if len(value) <5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajouter manuellement des thèmes plus larges\n",
    "add_themes = ['Immigration', 'Emploi']\n",
    "add_url_RI = parse_url(add_themes)\n",
    "add_tokens = get_tokens(add_url_RI,add_themes)\n",
    "champ_lexical_RI.update(add_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enlever les thèmes avec trop peu de mots-clés (< 10 mots)\n",
    "champ_lexical_RI = {i:champ_lexical_RI[i] for i in champ_lexical_RI if len(champ_lexical_RI[i]) > 10}\n",
    "\n",
    "# Garder uniquement les 30 premiers mots-clés de chaque thème\n",
    "restriction_tokens = {i:champ_lexical_RI[i][:30] for i in champ_lexical_RI if len(champ_lexical_RI[i]) < 30}\n",
    "\n",
    "# Constitution du champ lexical final\n",
    "champ_lexical_RI.update(restriction_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Vérification du nombre de mots composant chaque thème après filtre**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "longueur_EI = sorted([len(champ_lexical_EI[mot]) for mot in champ_lexical_EI])\n",
    "longueur_AE = sorted([len(champ_lexical_AE[mot]) for mot in champ_lexical_AE])\n",
    "longueur_RI = sorted([len(champ_lexical_RI[mot]) for mot in champ_lexical_RI])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "\n",
    "plt.bar([i for i in range(len(longueur_EI))], longueur_EI)\n",
    "plt.axhline(y=5, color = 'red')\n",
    "plt.axhline(y=30, color = 'purple')\n",
    "\n",
    "plt.xlabel('Thèmes')\n",
    "plt.ylabel('Nombre de mots')\n",
    "plt.title('Répartition du nombre de mots-clés pour chaque thème a priori pour la revue EI')\n",
    "plt.savefig('Plots/Validité_Wikipedia/repartition_champ_lexical_EI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.bar([i for i in range(len(longueur_AE))], longueur_AE)\n",
    "plt.axhline(y=5, color = 'red')\n",
    "plt.axhline(y=30, color = 'purple')\n",
    "plt.xlabel('Thèmes')\n",
    "plt.ylabel('Nombre de mots')\n",
    "plt.title('Répartition du nombre de mots-clés pour chaque thème a priori pour la revue AE')\n",
    "plt.savefig('Plots/Validité_Wikipedia/repartition_champ_lexical_AE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "plt.bar([i for i in range(len(longueur_RI))], longueur_RI)\n",
    "plt.axhline(y=5, color = 'red')\n",
    "plt.axhline(y=30, color = 'purple')\n",
    "plt.xlabel('Thèmes')\n",
    "plt.ylabel('Nombre de mots')\n",
    "plt.title('Répartition du nombre de mots-clés pour chaque thème a priori pour la revue RI')\n",
    "plt.savefig('Plots/Validité_Wikipedia/repartition_champ_lexical_RI')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Préparation des bigrammes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mise en minuscule et constitution des bigrammes\n",
    "def preprocess(champ_lexical):\n",
    "    champ_lexical_clean = {}\n",
    "    for index, tokens in champ_lexical.items():\n",
    "        champ_lexical_clean[index] = [token.replace(' ', '_').lower() for token in tokens]\n",
    "    return champ_lexical_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "champ_lexical_AE_clean = preprocess(champ_lexical_AE)\n",
    "champ_lexical_EI_clean = preprocess(champ_lexical_EI)\n",
    "champ_lexical_RI_clean = preprocess(champ_lexical_RI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store champ_lexical_EI_clean\n",
    "%store champ_lexical_AE_clean\n",
    "%store champ_lexical_RI_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mesure de similarité"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Récupération des thèmes a priori**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r champ_lexical_EI_clean\n",
    "%store -r champ_lexical_AE_clean\n",
    "%store -r champ_lexical_RI_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Récupération des thèmes des modèles LDA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def champ_lexical_LDA (model):\n",
    "    \"\"\"Retourner un dictionnaire pour un modèle lda donné sur une revue donnée de la forme \n",
    "        {num_topic : [liste tokens]}\"\"\"\n",
    "    dico_mots = {}\n",
    "    for theme in range(model.num_topics):\n",
    "        topics = model.show_topic(theme, 10)\n",
    "        dico_mots[theme] = [topics[i][0] for i in range(len(topics))]    \n",
    "    return dico_mots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def levenshteinDistance(s1, s2):\n",
    "    \"\"\"Mesure de string distance entre 2 string \"\"\"\n",
    "    if len(s1) > len(s2):\n",
    "        s1, s2 = s2, s1\n",
    "\n",
    "    distances = range(len(s1) + 1)\n",
    "    for i2, c2 in enumerate(s2):\n",
    "        distances_ = [i2+1]\n",
    "        for i1, c1 in enumerate(s1):\n",
    "            if c1 == c2:\n",
    "                distances_.append(distances[i1])\n",
    "            else:\n",
    "                distances_.append(1 + min((distances[i1], distances[i1 + 1], distances_[-1])))\n",
    "        distances = distances_\n",
    "    return distances[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarités_distance (champ_lexical_LDA, champ_lexical_clean):\n",
    "    \"\"\"Retourne les paires de thèmes (LDA, apriori) qui ont au moins un mot en commun ou deux mots à distance 1 l'un de l'autre\"\"\"\n",
    "    compte_similarités = {}\n",
    "    mots_proches = []\n",
    "    for num_topic,mots_LDA in champ_lexical_LDA.items():\n",
    "            for theme,mots_apriori in champ_lexical_clean.items():\n",
    "                for mot_1 in mots_LDA:\n",
    "                    for mot_2 in mots_apriori:\n",
    "                        if levenshteinDistance(mot_1,mot_2) <= 1:\n",
    "                            try : compte_similarités[(num_topic, theme)].append(mot_1)\n",
    "                            except : compte_similarités[(num_topic, theme)] = [mot_1] \n",
    "    return compte_similarités "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attribution_topiques (model, compte_similarités):\n",
    "    \"\"\"\"Retourne une étiquette à chaque thème avec les mots en commun\"\"\"\n",
    "    thèmes_LDA = dict.fromkeys([x for x in range(model.num_topics)], [])\n",
    "    for element in compte_similarités:\n",
    "        if thèmes_LDA[element[0]] == []:\n",
    "            thèmes_LDA[element[0]] = [(element[1], compte_similarités[element])]\n",
    "        else : \n",
    "            thèmes_LDA[element[0]].append((element[1],compte_similarités[element]))\n",
    "    return thèmes_LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_model = 'C:/Users/arten/OneDrive - polymtl.ca/Documents/Etudes/Montréal/Etudes/Projet de recherche/Code/Erudit/Résultats_LDA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choix du nombre de thèmes pour les modèles LDA\n",
    "num_topics = [x for x in range(10,110,10)]\n",
    "num_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computing_thèmes (champ_lexical_clean, revue = '/lda_ae_'):\n",
    "    \"\"\"Fonction pour itérer sur les différents modèles de thèmes pour une revue\"\"\"\n",
    "    thèmes_revue = dict.fromkeys([x for x in num_topics])\n",
    "    for i in num_topics:\n",
    "        print(path_model + revue + str(i))\n",
    "        model = LdaModel.load(path_model + revue + str(i))\n",
    "        champ_lexical = champ_lexical_LDA(model)\n",
    "        compte_similarités = similarités_distance(champ_lexical, champ_lexical_clean)\n",
    "        thèmes_revue[i] = attribution_topiques(model,compte_similarités)\n",
    "    return thèmes_revue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thèmes_revue_AE = computing_thèmes(champ_lexical_AE_clean, revue='/lda_ae_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store thèmes_revue_AE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thèmes_revue_EI = computing_thèmes(champ_lexical_EI_clean, revue='/lda_ei_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store thèmes_revue_EI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thèmes_revue_RI = computing_thèmes(champ_lexical_RI_clean, revue='/lda_ri_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store thèmes_revue_RI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) VALIDATION DU MODELE SUR UNE TACHE DE FOUILLE DE DOCUMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OBJECTIF**\n",
    "- Valider l'information thématique extraite avec le modèle LDA sur une tâche de fouille de documents\n",
    "\n",
    "**METHODE**\n",
    "- 1ère étape : Identifier les correspondances des thèmes entre LDA et a priori (descriptif)\n",
    "- 2ème étape : Identifier les documents dans la revue contenant les thèmes LDA majoritaires parmi ceux filtrés en 1ère étape\n",
    "- 3ème étape : Identifier les mots-clés (Sélection fréquentielle) contenus dans ces documents (constitution de (a))\n",
    "- 4ème étape : Etude quantitative des 4 méthodes de fouille : \n",
    "    - a) Fouille de documents à l'aide des mots-clés issus des documents majoritaires\n",
    "    - b) Fouille de documents à l'aide des mots-clés issus des thèmes a priori\n",
    "    - c) Fouille de documents à l'aide des mots-clés issus des thèmes LDA\n",
    "    - d) Fouille de documents à l'aide des distances dans l'espace latent lda (avec 3 modèles de thèmes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Etude comparative thèmes LDA et thèmes a priori"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Calcul du nombre de thèmes LDA identifiés avec un thème a priori**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r thèmes_revue_RI\n",
    "%store -r thèmes_revue_EI\n",
    "%store -r thèmes_revue_AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compte_cohérence(thèmes_revue):\n",
    "    \"\"\"Compte le nombre de thèmes LDA auquel au moins un thème a priori a pu être identifié\"\"\"\n",
    "    compte = []\n",
    "    for num_thème, dico_thèmes in thèmes_revue.items():\n",
    "        compteur = 0\n",
    "        for _ , thème in dico_thèmes.items():\n",
    "            if thème == []:\n",
    "                compteur +=1\n",
    "        compte.append((num_thème,compteur))\n",
    "    return compte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compte_cohérence_AE = compte_cohérence(thèmes_revue_AE)\n",
    "compte_cohérence_EI = compte_cohérence(thèmes_revue_EI)\n",
    "compte_cohérence_RI = compte_cohérence(thèmes_revue_RI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plots**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_save = \"Plots/Validité_Wikipedia/\"\n",
    "# Enregistré sur le One drive directement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [element[0] for element in compte_cohérence_AE]\n",
    "y = [int(element[1]/element[0]*100) for element in compte_cohérence_AE]\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.title(\"Pourcentage de thèmes incohérents en fonction de la capacité du modèle LDA pour la revue AE\")\n",
    "plt.xlabel(\"Nombre de thèmes du modèle LDA\")\n",
    "plt.ylabel(\"Pourcentage de thèmes incohérents\")\n",
    "plt.axhline(y = np.mean(y), color = 'orange')\n",
    "plt.bar(x,y)\n",
    "plt.savefig(path_save + \"pourcentage_incohérence_AE.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [element[0] for element in compte_cohérence_EI]\n",
    "y = [int(element[1]/element[0]*100) for element in compte_cohérence_EI]\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.title(\"Pourcentage de thèmes incohérents en fonction de la capacité du modèle LDA pour la revue EI\")\n",
    "plt.xlabel(\"Nombre de thèmes du modèle LDA\")\n",
    "plt.ylabel(\"Pourcentage de thèmes incohérents\")\n",
    "plt.axhline(y = np.mean(y), color = 'orange')\n",
    "plt.bar(x,y)\n",
    "plt.savefig(path_save + \"pourcentage_incohérence_EI.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [element[0] for element in compte_cohérence_RI]\n",
    "y = [int(element[1]/element[0]*100) for element in compte_cohérence_RI]\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.title(\"Pourcentage de thèmes incohérents en fonction de la capacité du modèle LDA pour la revue RI\")\n",
    "plt.xlabel(\"Nombre de thèmes du modèle LDA\")\n",
    "plt.ylabel(\"Pourcentage de thèmes incohérents\")\n",
    "plt.axhline(y = np.mean(y), color = 'orange')\n",
    "plt.bar(x,y)\n",
    "plt.savefig(path_save + \"pourcentage_incohérence_RI.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Filtre des thèmes LDA identifiés comme \"cohérents\" selon les thèmes a priori**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thèmes_revues_cohérents(thèmes_revue):\n",
    "    \"\"\"Retourne les thèmes LDA auquel au moins un thème a priori a pu être identifié\"\"\"\n",
    "    thèmes_cohérents = dict.fromkeys([x for x in num_topics])\n",
    "    for num_thème, dico_thèmes in thèmes_revue.items():\n",
    "        thèmes ={}\n",
    "        for index , thème in dico_thèmes.items():\n",
    "            if thème != []:\n",
    "                thèmes[index] = thème\n",
    "        thèmes_cohérents[num_thème] = thèmes\n",
    "    return thèmes_cohérents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thèmes_revue_cohérents_AE = thèmes_revues_cohérents(thèmes_revue_AE)\n",
    "thèmes_revue_cohérents_EI = thèmes_revues_cohérents(thèmes_revue_EI)\n",
    "thèmes_revue_cohérents_RI = thèmes_revues_cohérents(thèmes_revue_RI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store thèmes_revue_cohérents_AE\n",
    "%store thèmes_revue_cohérents_RI\n",
    "%store thèmes_revue_cohérents_EI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Identification des articles contenant la plus grande proportion de thèmes et récupération des tokens de ces articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r thèmes_revue_cohérents_AE\n",
    "%store -r thèmes_revue_cohérents_RI\n",
    "%store -r thèmes_revue_cohérents_EI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r corpus_train_AE\n",
    "%store -r corpus_train_EI\n",
    "%store -r corpus_train_RI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topics_document(ldamodel, corpus, texts):\n",
    "    \"\"\"Retourne une liste où chaque élément représente pour chaque article [index_thème_dominant, prop_thème, mots_clés_thème, tokens_article]\"\"\"\n",
    "    sentences = []\n",
    "    for i, row in enumerate(ldamodel[corpus]):\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # On récupère le thème majoritaire, sa contribution en % et les mots-clés du thème et les mots-clés du thème pour chaque document ainsi que les tokens du document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => on s'intéresse au thème dominant\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sentences.append([int(topic_num), round(prop_topic,4), topic_keywords,texts[i]])\n",
    "            else:\n",
    "                break\n",
    "    return(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtre_thèmes(sorted_sentences, thèmes_cohérents, ldamodel):\n",
    "    \"\"\"Retourner pour chaque thème LDA cohérent les 5 documents qui contiennent le plus de ce thème en proportion\n",
    "     Output = dictionnaire avec clé = index_thème et valeur = liste des tokens des 5 articles ayant ces thèmes en plus grande contribution\"\"\"\n",
    "    filtres = {}\n",
    "    for index_thème, autre in thèmes_cohérents[ldamodel.num_topics].items():\n",
    "        filtre = []\n",
    "        for element in sorted_sentences:\n",
    "            if element[0] == index_thème and len(filtre)<5 :\n",
    "                filtre.append(element[3])\n",
    "        filtres[index_thème] = filtre\n",
    "    return filtres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Récupération des modèles**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r train_texts_AE\n",
    "%store -r train_texts_EI\n",
    "%store -r train_texts_RI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_model = 'C:/Users/arten/OneDrive - polymtl.ca/Documents/Etudes/Montréal/Etudes/Projet de recherche/Code/Erudit/Résultats_LDA'\n",
    "i = 10 # nombre de thèmes du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AE\n",
    "revue = '/lda_ae_'\n",
    "model_ae_10 = LdaModel.load(path_model + revue + str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EI\n",
    "revue = '/lda_ei_'\n",
    "model_ei_10 = LdaModel.load(path_model + revue + str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AE\n",
    "revue = '/lda_ri_'\n",
    "model_ri_10 = LdaModel.load(path_model + revue + str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_AE = get_topics_document(ldamodel=model_ae_10, corpus=corpus_train_AE, texts=train_texts_AE)\n",
    "sentences_EI = get_topics_document(ldamodel=model_ei_10, corpus=corpus_train_EI, texts=train_texts_EI)\n",
    "sentences_RI = get_topics_document(ldamodel=model_ri_10, corpus=corpus_train_RI, texts=train_texts_RI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trier la liste selon les thèmes dominants et les proportion de ces thèmes au sein des articles\n",
    "sorted_sentences_AE = sorted(sentences_AE, key =lambda tup:(tup[0],tup[1]), reverse=True) \n",
    "sorted_sentences_EI = sorted(sentences_EI, key =lambda tup:(tup[0],tup[1]), reverse=True) \n",
    "sorted_sentences_RI = sorted(sentences_RI, key =lambda tup:(tup[0],tup[1]), reverse=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_sentences_EI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtre_thèmes_AE = filtre_thèmes(sorted_sentences = sorted_sentences_AE, thèmes_cohérents = thèmes_revue_cohérents_AE, ldamodel = model_ae_10)\n",
    "filtre_thèmes_EI = filtre_thèmes(sorted_sentences = sorted_sentences_EI, thèmes_cohérents = thèmes_revue_cohérents_EI, ldamodel = model_ei_10)\n",
    "filtre_thèmes_RI = filtre_thèmes(sorted_sentences = sorted_sentences_RI, thèmes_cohérents = thèmes_revue_cohérents_RI, ldamodel = model_ri_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store filtre_thèmes_AE \n",
    "%store filtre_thèmes_EI \n",
    "%store filtre_thèmes_RI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Sélection fréquentielle des tokens présents dans les 5 articles majoritaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r filtre_thèmes_AE \n",
    "%store -r filtre_thèmes_EI \n",
    "%store -r filtre_thèmes_RI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtre_tokens(filtre_thèmes, diversité = 10):\n",
    "    \"\"\"Constituer un vocabulaire de mots-clés associés à chaque thème à partir des articles où ces thèmes sont les plus importants\n",
    "    Paramètres : \n",
    "    - diversité = nombre de tokens différents récupérés dans chaque article\n",
    "    le vocabulaire total sera de 5 * diversité\"\"\"\n",
    "    \n",
    "    vocabulaire_thèmes = {}\n",
    "    for theme, liste_article in filtre_thèmes.items():\n",
    "        voca = []\n",
    "        for article in liste_article:\n",
    "            count = collections.Counter(article)\n",
    "            count = count.most_common(diversité)\n",
    "            for element in count:\n",
    "                    voca.append(element[0])\n",
    "        vocabulaire_thèmes[theme] = voca\n",
    "    return vocabulaire_thèmes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voca_AE_docmaj = filtre_tokens(filtre_thèmes_AE, diversité = 10)\n",
    "voca_EI_docmaj = filtre_tokens(filtre_thèmes_EI, diversité = 10)\n",
    "voca_RI_docmaj = filtre_tokens(filtre_thèmes_RI, diversité = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store voca_AE_docmaj\n",
    "%store voca_EI_docmaj\n",
    "%store voca_RI_docmaj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Tâche de fouille de documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### i. Préparation des listes de mots-clés"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constitution et récupération des 4 listes de mots-clés pour la recherche :\n",
    "- Liste issues des tokens des articles majoritaires de chaque thème = **voca_AE_docmaj - voca_EI_docmaj - voca_RI_docmaj**\n",
    "- Liste issues des thèmes a priori dont on a trouvé une similarité avec thèmes LDA : **voca_AE_apriori - voca_EI_apriori - voca_RI_apriori**\n",
    "- Liste issues des tokens de chaque thème LDA : **voca_AE_LDA - voca_EI_LDA - voca_RI_LDA**\n",
    "- Liste de tokens aléatoires issus du vocabulaire de l'ensemble de la revue : **voca_AE_random - voca_EI_random - voca_RI_random**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**a) Voca issu des thèmes des documents majoritaires**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabulaire de mots-clés (50 par thème) issus des 5 documents où les thèmes LDA étaient les plus présents\n",
    "%store -r voca_AE_docmaj\n",
    "%store -r voca_EI_docmaj\n",
    "%store -r voca_RI_docmaj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b) Voca issu des thèmes a priori**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Champ lexical de chaque thème a priori sous forme de dictionnaire\n",
    "%store -r champ_lexical_EI_clean\n",
    "%store -r champ_lexical_AE_clean\n",
    "%store -r champ_lexical_RI_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correspondances entre thèmes LDA et thèmes a priori\n",
    "%store -r thèmes_revue_cohérents_AE\n",
    "%store -r thèmes_revue_cohérents_RI\n",
    "%store -r thèmes_revue_cohérents_EI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On ne garde que les thèmes a priori dont on a trouvé une correspondance avec un thème LDA\n",
    "def voca_apriori(thèmes_revue_cohérents, champ_lexical_clean, num_topics=10):\n",
    "    \"\"\"Retourne un dictionnaire avec chaque élément du type [index_thème_LDA, liste de tokens des thèmes a priori associés]\"\"\"\n",
    "    themes_apriori = {}\n",
    "    for thème_LDA, element in thèmes_revue_cohérents[num_topics].items():      \n",
    "        themes_apriori[thème_LDA] = [element[i][0] for i in range(len(element))]\n",
    "    \n",
    "    print(themes_apriori)\n",
    "    voca_apriori = {}\n",
    "    for index, theme in themes_apriori.items():\n",
    "        try:\n",
    "            voca_apriori[index] = champ_lexical_clean[theme]\n",
    "        except: \n",
    "            voca_apriori[index] = [champ_lexical_clean[theme[i]] for i in range(len(theme))]\n",
    "        voca_apriori[index] = [element for sublist in voca_apriori[index] for element in sublist] # flatten list of list\n",
    "    \n",
    "    return voca_apriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voca_AE_apriori = voca_apriori(thèmes_revue_cohérents_AE, champ_lexical_AE_clean, num_topics=10)\n",
    "voca_EI_apriori = voca_apriori(thèmes_revue_cohérents_EI, champ_lexical_EI_clean, num_topics=10)\n",
    "voca_RI_apriori = voca_apriori(thèmes_revue_cohérents_RI, champ_lexical_RI_clean, num_topics=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mots-clés des thèmes a priori\n",
    "%store voca_AE_apriori\n",
    "%store voca_EI_apriori\n",
    "%store voca_RI_apriori"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c) Voca issu des thèmes LDA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voca_LDA(ldamodel):\n",
    "    \"\"\"Retourne les tokens de chaque thème\"\"\"\n",
    "    voca = {}\n",
    "    for theme in range(ldamodel.num_topics):\n",
    "        voca[theme] = [mot for mot, _ in ldamodel.show_topic(theme)]\n",
    "    return(voca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voca_AE_LDA = voca_LDA(model_ae_10)\n",
    "voca_EI_LDA = voca_LDA(model_ei_10)\n",
    "voca_RI_LDA = voca_LDA(model_ri_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store voca_AE_LDA\n",
    "%store voca_EI_LDA\n",
    "%store voca_RI_LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**d) Voca issus de thèmes random**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r dictionary_AE_2 \n",
    "%store -r dictionary_EI_2 \n",
    "%store -r dictionary_RI_2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voca_aléatoire(dictionary):\n",
    "    voca = [mots for mots in dictionary_AE_2.values()]\n",
    "    random.shuffle(voca)\n",
    "    return voca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voca_AE_aléatoire = voca_aléatoire(dictionary_AE_2)\n",
    "voca_EI_aléatoire = voca_aléatoire(dictionary_EI_2)\n",
    "voca_RI_aléatoire = voca_aléatoire(dictionary_RI_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store voca_AE_aléatoire\n",
    "%store voca_EI_aléatoire\n",
    "%store voca_RI_aléatoire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii. Requête et évaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BUT :  Trouver les documents du corpus les plus pertinents sur un thème d'intérêt a priori"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### METHODE\n",
    "\n",
    "*Répéter pour chaque revue et chaque thème apriori*\n",
    "\n",
    "A) Choisir un thème a priori et identifier les thèmes LDA associés (à l'aide de thèmes_revue_cohérents)\n",
    "\n",
    "B) Constituer le corpus sur lequel on applique la requête\n",
    "\n",
    "C) Fouiller le contenu des documents à l'aide des mots-clés associés à :\n",
    "- 10 mots-clés du thème a priori\n",
    "- 10 mots-clés des thèmes LDA associé à ce thème apriori\n",
    "- 10 mots-clés issus des documents où les thèmes LDA sont majoritaires\n",
    "- 10 mots-clés aléatoire du vocabulaire total\n",
    "\n",
    "Retourner les 5 documents du corpus les plus pertinents \n",
    "\n",
    "**1ère mesure de pertinence = Compter le nombre d'occurences des mots-clés dans leur contenu pour chacune des méthode de fouille**\n",
    "\n",
    "**2ème mesure de pertinence = Mesure de similarité cosinus entre le vecteur de requête et les vecteurs des documents au sein de la représentation LDA**\n",
    "\n",
    "D) Analyse visuelle de pertinence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Méthode 1 : Mesure en fréquence**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupération des 4 listes de vocabulaire (pour 10 topics)\n",
    "%store -r voca_AE_docmaj\n",
    "%store -r voca_EI_docmaj\n",
    "%store -r voca_RI_docmaj\n",
    "\n",
    "%store -r voca_AE_apriori\n",
    "%store -r voca_EI_apriori\n",
    "%store -r voca_RI_apriori\n",
    "\n",
    "%store -r voca_AE_LDA\n",
    "%store -r voca_EI_LDA\n",
    "%store -r voca_RI_LDA\n",
    "\n",
    "%store -r voca_AE_aléatoire\n",
    "%store -r voca_EI_aléatoire\n",
    "%store -r voca_RI_aléatoire\n",
    "\n",
    "# Correspondances entre thèmes LDA et thèmes a priori\n",
    "%store -r thèmes_revue_cohérents_AE\n",
    "%store -r thèmes_revue_cohérents_RI\n",
    "%store -r thèmes_revue_cohérents_EI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r tokens_bigrams_Corpus_LDA_AE_clean\n",
    "%store -r tokens_bigrams_Corpus_LDA_EI_clean\n",
    "%store -r tokens_bigrams_Corpus_LDA_RI_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r Corpus_AE\n",
    "%store -r Corpus_EI\n",
    "%store -r Corpus_RI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A) Constituer le corpus de requête **(TOURNER 1 FOIS SEULEMENT)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url_metadata (Corpus, tokens):\n",
    "    \"\"\"Prend en paramètre le Corpus avec textes et métadonnées et retourne le Corpus filtré avec les articles en français et de type article\n",
    "    + les tokens nettoyés pour chacun d'entre eux et l'URL\"\"\"\n",
    "    Corpus_filtre = []\n",
    "    index_clean = 0\n",
    "    for index_document in tqdm(range(len(Corpus))) :\n",
    "    # on ne traite que les articles de type article et en français\n",
    "        if (Corpus[index_document]['metadata']['typeart'], Corpus[index_document]['metadata']['lang']) == ('article','fr') : \n",
    "            Corpus_filtre.append((Corpus[index_document]['URL'], tokens[index_clean]))\n",
    "            index_clean +=1\n",
    "    return Corpus_filtre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Corpus_fouille_AE = get_url_metadata(Corpus_AE, tokens_bigrams_Corpus_LDA_AE_clean)\n",
    "Corpus_fouille_EI = get_url_metadata(Corpus_EI, tokens_bigrams_Corpus_LDA_EI_clean)\n",
    "Corpus_fouille_RI = get_url_metadata(Corpus_RI, tokens_bigrams_Corpus_LDA_RI_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store Corpus_fouille_AE\n",
    "%store Corpus_fouille_EI\n",
    "%store Corpus_fouille_RI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COTE UTILISATEUR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B) Retourner pour un thème a priori le numéro thèmes LDA candidats (parcours dico inverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topics_lda(thèmes_revue_cohérents,theme = 'Économie', num_topics=10):\n",
    "    \"\"\"Retourne la liste des numéros des thèmes LDA dont le thème a priori partage un ou plusieurs mots-clés\"\"\"\n",
    "    themes_lda = []\n",
    "    for theme_LDA, element in thèmes_revue_cohérents[num_topics].items():\n",
    "        for i in range(len(element)):\n",
    "            if element[i][0] == theme: themes_lda.append(theme_LDA)\n",
    "    return themes_lda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C) Fouille à l'aide des 4 méthodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r Corpus_fouille_AE\n",
    "%store -r Corpus_fouille_EI\n",
    "%store -r Corpus_fouille_RI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r tokens_bigrams_Corpus_LDA_AE_clean\n",
    "%store -r tokens_bigrams_Corpus_LDA_EI_clean\n",
    "%store -r tokens_bigrams_Corpus_LDA_RI_clean\n",
    "\n",
    "texts_AE = tokens_bigrams_Corpus_LDA_AE_clean\n",
    "texts_EI = tokens_bigrams_Corpus_LDA_EI_clean\n",
    "texts_RI = tokens_bigrams_Corpus_LDA_RI_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupération des 4 listes de vocabulaire (pour 10 topics)\n",
    "%store -r voca_AE_docmaj\n",
    "%store -r voca_EI_docmaj\n",
    "%store -r voca_RI_docmaj\n",
    "\n",
    "%store -r voca_AE_apriori\n",
    "%store -r voca_EI_apriori\n",
    "%store -r voca_RI_apriori\n",
    "\n",
    "%store -r voca_AE_LDA\n",
    "%store -r voca_EI_LDA\n",
    "%store -r voca_RI_LDA\n",
    "\n",
    "%store -r voca_AE_aléatoire\n",
    "%store -r voca_EI_aléatoire\n",
    "%store -r voca_RI_aléatoire\n",
    "\n",
    "# Correspondances entre thèmes LDA et thèmes a priori\n",
    "%store -r thèmes_revue_cohérents_AE\n",
    "%store -r thèmes_revue_cohérents_RI\n",
    "%store -r thèmes_revue_cohérents_EI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "champ_lexical_AE.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thèmes a priori\n",
    "%store -r champ_lexical_AE\n",
    "%store -r champ_lexical_EI\n",
    "%store -r champ_lexical_RI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_corpus(mots_clés, texts):\n",
    "    \"\"\"Retourne un dictionnaire avec index des articles où se trouvent les mots clés + compteur d'occurrences des mots-clés\"\"\"\n",
    "    documents_found = {}\n",
    "    for text in texts:\n",
    "        documents_found[texts.index(text)] = 0\n",
    "        for mot in mots_clés:\n",
    "            if text.count(mot) != 0 : documents_found[texts.index(text)] += text.count(mot)\n",
    "    return documents_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fouille_corpus(themes_lda, corpus_fouille = Corpus_fouille_AE, texts= texts_AE, voca_LDA = voca_AE_LDA, voca_docmaj =voca_AE_docmaj, voca_apriori = voca_AE_apriori, voca_aléatoire = voca_AE_aléatoire):\n",
    "    \"\"\"Input : un intérêt de recherche qui nous sert de clé de recherche dans le corpus\n",
    "        + 4 vocabulaires construits à l'aide de méthodes différentes : thèmes LDA - thèmes des documents où le thème est majoritaire - thèmes a_priori - mots aléatoires\n",
    "        Output : Pour chaque méthode, sortir 5 documents plus pertinents pour l'intérêt de recherche\"\"\"\n",
    "    \n",
    "    # Modifier l'index (pour idnex=0 : on ne prend qu'un seul thème LDA proche des thèmes a priori)\n",
    "    index_lda = themes_lda[0]\n",
    "    \n",
    "    documents = {}\n",
    "    # Mots-clés issus des thèmes LDA\n",
    "    requete = search_corpus(voca_LDA[index_lda], texts)\n",
    "    documents['LDA'] = sorted(requete.items(), key=lambda x:x[1], reverse = True)[:5] # 5 premiers documents\n",
    "    \n",
    "    # Mots-clés issus des documents majoritair\n",
    "    requete = search_corpus(voca_docmaj[index_lda], texts)\n",
    "    documents['docmaj'] = sorted(requete.items(), key=lambda x:x[1], reverse = True)[:5]\n",
    "    \n",
    "    # Mots-clés issus des thèmes a priori\n",
    "    requete = search_corpus(voca_apriori[index_lda], texts)\n",
    "    documents['apriori'] = sorted(requete.items(), key=lambda x:x[1], reverse = True)[:5]\n",
    "    \n",
    "    # Mots-clés issus des documents majoritaires\n",
    "    \n",
    "    requete = search_corpus(voca_aléatoire[0:10], texts)\n",
    "    documents['aléatoire'] = sorted(requete.items(), key=lambda x:x[1], reverse = True)[:5]\n",
    "    \n",
    "    URLS = {}\n",
    "    for voca, liste in documents.items():\n",
    "        urls = []\n",
    "        for i in range(5):\n",
    "            url = documents[voca][i][0]\n",
    "            urls.append(corpus_fouille[url][0])\n",
    "        URLS[voca] = urls\n",
    "    \n",
    "    return documents, URLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title_from_URL (URL):\n",
    "    r = requests.get(URL + '/ERUDITXSD300.xml', auth=('mgagnon', 'iathe6eiyaiy6Eic')) \n",
    "    soup = BeautifulSoup(r.text, \"lxml\")\n",
    "    return soup.titre.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def requête_lda_frequence(revue = 'ae', theme = None, num_topics=10,thèmes_revue_cohérents=thèmes_revue_cohérents_AE, \n",
    "                          texts= texts_AE, voca_LDA = voca_AE_LDA, voca_docmaj =voca_AE_docmaj, voca_apriori = voca_AE_apriori, voca_aléatoire = voca_AE_aléatoire, print_=True, save=True):\n",
    "    t0 = time.time()\n",
    "    if theme == None:\n",
    "        theme = input(\"Veuillez entrer votre requête ici :\")\n",
    "    \n",
    "    themes_lda = get_topics_lda(theme = theme, num_topics=num_topics, thèmes_revue_cohérents=thèmes_revue_cohérents)\n",
    "    requete, URLS = fouille_corpus(themes_lda = themes_lda, texts= texts, voca_LDA = voca_LDA, voca_docmaj =voca_docmaj, voca_apriori = voca_apriori, voca_aléatoire = voca_aléatoire)\n",
    "    \n",
    "    print(\"Fin de la conversion de la requête en \", round(time.time()-t0,0), \"secondes\")\n",
    "    # Récupération des titres des articles\n",
    "    data = dict.fromkeys(URLS.keys())\n",
    "    for key, value in tqdm(URLS.items()):\n",
    "        for URL in value:\n",
    "            try :\n",
    "                data[key].append(get_title_from_URL(URL))\n",
    "            except : \n",
    "                data[key] = [get_title_from_URL(URL)]\n",
    "    if print_:\n",
    "        print(pd.DataFrame(data))\n",
    "    \n",
    "    if save: \n",
    "        pd.DataFrame(data).to_csv(\"Plots/LDA/fouille/\"+revue +\"/fouille_frequence_\" + revue +\"_query=\"+theme+\"_num_topics=\" + str(num_topics) +\".csv\")\n",
    "        \n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "themes_lda = get_topics_lda(theme = 'Économétrie', num_topics=10, thèmes_revue_cohérents=thèmes_revue_cohérents_AE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "themes_lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(voca_AE_LDA[themes_lda[0]],'\\n \\n',voca_AE_docmaj[themes_lda[0]], '\\n \\n', voca_AE_apriori[themes_lda[0]], '\\n \\n', voca_AE_aléatoire[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultat_AE = requête_lda_frequence(revue = 'ae', num_topics=10,thèmes_revue_cohérents=thèmes_revue_cohérents_AE, \n",
    "                                  texts= texts_AE, voca_LDA = voca_AE_LDA, voca_docmaj =voca_AE_docmaj, voca_apriori = voca_AE_apriori, voca_aléatoire = voca_AE_aléatoire, print_=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for theme in champ_lexical_EI.keys():\n",
    "    themes_lda = get_topics_lda(theme = theme, num_topics=10, thèmes_revue_cohérents=thèmes_revue_cohérents_EI)\n",
    "    print(themes_lda,theme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultat_EI = requête_lda_frequence(revue = 'ei', num_topics=10,thèmes_revue_cohérents=thèmes_revue_cohérents_EI, \n",
    "                                  texts= texts_EI, voca_LDA = voca_EI_LDA, voca_docmaj =voca_EI_docmaj, voca_apriori = voca_EI_apriori, voca_aléatoire = voca_EI_aléatoire, print_=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultat_EI = requête_lda_frequence(revue = 'ei', num_topics=10,thèmes_revue_cohérents=thèmes_revue_cohérents_EI, \n",
    "                                  texts= texts_EI, voca_LDA = voca_EI_LDA, voca_docmaj =voca_EI_docmaj, voca_apriori = voca_EI_apriori, voca_aléatoire = voca_EI_aléatoire, print_=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for theme in champ_lexical_RI.keys():\n",
    "    themes_lda = get_topics_lda(theme = theme, num_topics=10, thèmes_revue_cohérents=thèmes_revue_cohérents_RI)\n",
    "    print(themes_lda,theme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultat_RI = requête_lda_frequence(revue = 'ri', num_topics=10,thèmes_revue_cohérents=thèmes_revue_cohérents_RI, \n",
    "                                  texts= texts_RI, voca_LDA = voca_RI_LDA, voca_docmaj =voca_RI_docmaj, voca_apriori = voca_RI_apriori, voca_aléatoire = voca_RI_aléatoire, print_=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultat_RI = requête_lda_frequence(revue = 'ri', num_topics=10,thèmes_revue_cohérents=thèmes_revue_cohérents_RI, \n",
    "                                  texts= texts_RI, voca_LDA = voca_RI_LDA, voca_docmaj =voca_RI_docmaj, voca_apriori = voca_RI_apriori, voca_aléatoire = voca_RI_aléatoire, print_=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Influence du nombre de thèmes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il faut créer un vocabulaire pour chaque thème spécifique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = [x for x in range(10,110,10)]\n",
    "num_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_themes_for_all_topics (theme = 'Économie', thèmes_revue =thèmes_revue_cohérents_AE):\n",
    "    \"\"\"Retourne pour chaque topic model l'index des thèmes LDA qui ont au moins un mot en commun avec le thème recherché\"\"\"\n",
    "    themes = dict.fromkeys(num_topics)\n",
    "    for topic in tqdm(num_topics):\n",
    "        themes[topic] = get_topics_lda(theme = theme, num_topics=topic, thèmes_revue_cohérents= thèmes_revue)\n",
    "    return themes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "themes_AE = get_themes_for_all_topics(theme = 'Économie', thèmes_revue =thèmes_revue_cohérents_AE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "themes_AE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Méthode 2 : Mesure de similarité cosinus dans l'espace LDA**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TOURNER UNE SEULE FOIS : création des index pour chaque modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexation des documents du corpus pour fouiller plus rapidement\n",
    "%store -r dictionary_AE_2\n",
    "dictionary = dictionary_AE_2\n",
    "revue = '/lda_ae_'\n",
    "corpus_lda_AE = [dictionary.doc2bow(doc) for doc in tokens_bigrams_Corpus_LDA_AE_clean]\n",
    "\n",
    "for topic in tqdm(range(10,110,10)):\n",
    "    model = models.LdaModel.load('Résultats_LDA'+ revue + str(topic))\n",
    "    index = similarities.MatrixSimilarity(model[corpus_lda_AE])\n",
    "    index.save('Variables résultats/index/index_ae_' + str(topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modèles fiabilité\n",
    "%store -r dictionary_AE_2\n",
    "dictionary = dictionary_AE_2\n",
    "revue = '/lda_ae_'\n",
    "corpus_lda_AE = [dictionary.doc2bow(doc) for doc in tokens_bigrams_Corpus_LDA_AE_clean]\n",
    "\n",
    "for topic in tqdm(range(5)):\n",
    "    model = models.LdaModel.load('Résultats_LDA/Fiabilité'+ revue + str(10) +\"_\"+str(topic))\n",
    "    index = similarities.MatrixSimilarity(model[corpus_lda_AE])\n",
    "    index.save('Variables résultats/index/index_ae_' + str(topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexation des documents du corpus pour fouiller plus rapidement\n",
    "%store -r dictionary_EI_2\n",
    "dictionary = dictionary_EI_2\n",
    "revue = '/lda_ei_'\n",
    "corpus_lda = [dictionary.doc2bow(doc) for doc in tokens_bigrams_Corpus_LDA_EI_clean]\n",
    "\n",
    "for topic in tqdm(range(10,110,10)):\n",
    "    model = models.LdaModel.load('Résultats_LDA'+ revue + str(topic))\n",
    "    index = similarities.MatrixSimilarity(model[corpus_lda])\n",
    "    index.save('Variables résultats/index/index_ei_' + str(topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indexation des documents du corpus pour fouiller plus rapidement\n",
    "%store -r dictionary_RI_2\n",
    "dictionary = dictionary_RI_2\n",
    "revue = '/lda_ri_'\n",
    "corpus_lda = [dictionary.doc2bow(doc) for doc in tokens_bigrams_Corpus_LDA_RI_clean]\n",
    "\n",
    "for topic in tqdm(range(10,110,10)):\n",
    "    model = models.LdaModel.load('Résultats_LDA'+ revue + str(topic))\n",
    "    index = similarities.MatrixSimilarity(model[corpus_lda])\n",
    "    index.save('Variables résultats/index/index_ri_' + str(topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COTE UTILISATEUR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r dictionary_AE_2\n",
    "%store -r dictionary_EI_2\n",
    "%store -r dictionary_RI_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_title_from_URL (URL):\n",
    "    r = requests.get(URL + '/ERUDITXSD300.xml', auth=('mgagnon', 'iathe6eiyaiy6Eic')) \n",
    "    soup = BeautifulSoup(r.text, \"lxml\")\n",
    "    print(URL, ' : ', soup.titre.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title_and_URL (indexes, corpus=Corpus_fouille_AE):\n",
    "    data = []\n",
    "    for index in indexes:\n",
    "        URL = corpus[index][0]\n",
    "        r = requests.get(URL + '/ERUDITXSD300.xml', auth=('mgagnon', 'iathe6eiyaiy6Eic')) \n",
    "        soup = BeautifulSoup(r.text, \"lxml\")\n",
    "        data.append(soup.titre.text)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def requête_LDA(revue = 'ae', num_topics=0, corpus = Corpus_fouille_AE, dictionary= dictionary_AE_2, query = None, print_=True, get=True, fiabilité=False):\n",
    "    \"\"\"Fonction pour permettre la recherche de mots-clés dans le corpus à l'aide de la similarité cosinus\"\"\"\n",
    "    \n",
    "    if fiabilité==True:\n",
    "        model = models.LdaModel.load('Résultats_LDA/Fiabilité/lda_'+ revue +'_'+ str(10) +\"_\"+str(topic))\n",
    "        index = similarities.MatrixSimilarity.load('Variables résultats/index/index_' + revue + '_' + str(num_topics))\n",
    "    else:\n",
    "        model = models.LdaModel.load('Résultats_LDA/'+revue+ '/lda_'+ revue + '_'+str(num_topics))\n",
    "        index = similarities.MatrixSimilarity.load('Variables résultats/index/index_' + revue + '_' + str(num_topics))\n",
    "    \n",
    "    if query == None:\n",
    "        query = input('Veuillez entrer votre requête : ')\n",
    "\n",
    "    # Transformation du string en matrice BoW\n",
    "    vec_query = dictionary.doc2bow(query.lower().split())    \n",
    "    \n",
    "    # Requête placée dans l'espace du modèle LDA\n",
    "    vec_lda = model[vec_query]\n",
    "\n",
    "    # Récupération des documents les plus proches du vecteur de requête\n",
    "    sims = index[vec_lda]\n",
    "    sims = sorted(enumerate(sims), key=lambda item: -item[1]) # ordonnement par ordre décroissant de similarité cosinus\n",
    "\n",
    "    ##### Récupération des index des documents les plus pertinents et impression des URL associés\n",
    "    indexes = [i[0] for i in sims[:5]]\n",
    "    \n",
    "    if print_:\n",
    "        for index in indexes:\n",
    "            print_title_from_URL(corpus[index][0])\n",
    "    \n",
    "    if get:\n",
    "        resultat = get_title_and_URL(indexes,corpus)\n",
    "        return resultat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple\n",
    "resultat_AE = requête_LDA(revue = 'ae', num_topics=10, corpus = Corpus_fouille_AE, dictionary = dictionary_AE_2, print_=True, get=True, fiabilité=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple\n",
    "resultat_AE = requête_LDA(revue = 'ae', query='Macroéconomie', num_topics=4, corpus = Corpus_fouille_AE, dictionary = dictionary_AE_2, print_=True, get=True, fiabilité=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultat_EI = requête_LDA(revue = 'ei', corpus = Corpus_fouille_EI, dictionary = dictionary_EI_2, num_topics=50, print_=True, get=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultat_RI = requête_LDA(revue = 'ri', corpus = Corpus_fouille_RI, dictionary = dictionary_RI_2, num_topics=50, print_=True, get=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Etude de l'influence du nombre de thèmes sur le résultat de la requête**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def influence_thèmes(query=None, save = True, print_=True, topic_max=30, revue='ae',corpus = Corpus_fouille_AE, dictionary = dictionary_AE_2):\n",
    "    if query == None:\n",
    "        query=input(\"Entrez vore requête ici : \")\n",
    "    data={}\n",
    "    for topic in tqdm(range(10, topic_max+10,10)):\n",
    "        data[topic] = requête_LDA(revue = revue, corpus = corpus, dictionary = dictionary, num_topics=topic, query=query, get=True, print_=False)\n",
    "        \n",
    "    if save == True:\n",
    "        pd.DataFrame(data).to_csv(\"Plots/LDA/fouille/\"+ revue +\"/fouille_\" +revue +\"_query=\"+query+\".csv\")\n",
    "    \n",
    "    if print_ == True :\n",
    "        pd.DataFrame(data).head()\n",
    "        \n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "panda = influence_thèmes(save=True, print_=True, topic_max=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "panda.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "panda = influence_thèmes(query='politique monétaire',save=False, print_=True, topic_max=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "panda = influence_thèmes(query='Économie du travail',save=True, print_=True, topic_max=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "panda = influence_thèmes(query='Méthodes numériques',save=True, print_=True, topic_max=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**EI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "panda = influence_thèmes(save=True, print_=True, topic_max=50, revue='ei',corpus = Corpus_fouille_EI, dictionary = dictionary_EI_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "panda.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "panda = influence_thèmes(query='Sécurité internationale',save=True, print_=True, topic_max=50, revue='ei',corpus = Corpus_fouille_EI, dictionary = dictionary_EI_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "panda = influence_thèmes(query='afrique',save=True, print_=True, topic_max=50, revue='ei',corpus = Corpus_fouille_EI, dictionary = dictionary_EI_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "panda = influence_thèmes(query='Relations nord-sud',save=True, print_=True, topic_max=50, revue='ei',corpus = Corpus_fouille_EI, dictionary = dictionary_EI_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for theme in champ_lexical_RI.keys():\n",
    "    themes_lda = get_topics_lda(theme = theme, num_topics=10, thèmes_revue_cohérents=thèmes_revue_cohérents_RI)\n",
    "    print(themes_lda,theme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "panda = influence_thèmes(save=True, print_=True, topic_max=50, revue='ri',corpus = Corpus_fouille_RI, dictionary = dictionary_RI_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "panda = influence_thèmes(query='Droits de la personne',save=True, print_=True, topic_max=50, revue='ri',corpus = Corpus_fouille_RI, dictionary = dictionary_RI_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "panda = influence_thèmes(query='Temps de travail',save=True, print_=True, topic_max=50, revue='ri',corpus = Corpus_fouille_RI, dictionary = dictionary_RI_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calcul du ${\\alpha}$ de Krippendorff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BUT\n",
    "\n",
    "- Calcul du alpha de Krippendorff pour valider la fidélité interjuges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import krippendorff\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_AE = (\"3\t2\t3\t4\t1\t3\t3\t1\t2\t4\t4\t1\t2\t3\t1\t5\t4\t2\",\n",
    "\"4\t2\t1\t2\t4\t3\t2\t3\t1\t4\t1\t3\t4\t1\t1\t3\t1\t1\",\n",
    "\"3\t3\t3\t4\t3\t3\t5\t1\t2\t5\t4\t1\t3\t4\t1\t5\t2\t1\",\n",
    "\"3\t3\t4\t3\t2\t3\t4\t1\t3\t3\t3\t1\t2\t4\t2\t4\t3\t2\",\n",
    "\"3\t3\t4\t3\t2\t3\t3\t2\t3\t3\t4\t2\t3\t4\t2\t4\t4\t2\",\n",
    "\"3\t2\t2\t4\t1\t2\t3\t1\t3\t3\t3\t1\t2\t4\t2\t5\t5\t1\",\n",
    "\"3\t3\t3\t5\t2\t2\t4\t1\t3\t3\t4\t2\t2\t4\t1\t3\t4\t2\",\n",
    "\"3\t3\t3\t3\t2\t2\t3\t1\t3\t3\t3\t2\t3\t2\t3\t3\t3\t3\",\n",
    "\"3\t2\t4\t3\t1\t2\t3\t1\t3\t4\t2\t1\t4\t5\t1\t4\t4\t2\",\n",
    "\"3\t2\t3\t3\t2\t2\t4\t2\t4\t3\t4\t1\t3\t4\t1\t3\t4\t2\",\n",
    "\"4\t3\t4\t5\t2\t2\t4\t1\t3\t5\t5\t2\t3\t5\t2\t5\t5\t2\",\n",
    "\"2\t3\t2\t5\t1\t2\t3\t1\t3\t3\t4\t1\t4\t2\t2\t5\t3\t1\",\n",
    "\"4\t4\t4\t4\t3\t3\t3\t2\t3\t4\t4\t2\t3\t3\t2\t4\t4\t4\",\n",
    "\"4\t2\t2\t2\t1\t2\t4\t1\t2\t3\t2\t1\t2\t4\t1\t4\t3\t2\",\n",
    "\"3\t3\t3\t3\t3\t2\t3\t2\t3\t3\t3\t3\t2\t3\t2\t3\t3\t2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_EI = (\"1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t2\t4\t4\t4\t3\t2\t3\",\n",
    "\"2\t1\t1\t1\t1\t2\t1\t1\t1\t4\t3\t3\t5\t5\t5\t2\t2\t3\",\n",
    "\"2\t1\t2\t3\t1\t1\t3\t1\t2\t4\t4\t5\t5\t5\t4\t4\t5\t4\",\n",
    "\"1\t1\t1\t1\t1\t1\t1\t1\t1\t2\t2\t2\t2\t3\t2\t1\t2\t1\",\n",
    "\"2\t1\t2\t2\t2\t1\t2\t1\t2\t3\t3\t3\t3\t4\t3\t3\t3\t3\",\n",
    "\"2\t2\t2\t2\t2\t2\t2\t2\t1\t2\t2\t2\t2\t2\t2\t2\t2\t2\",\n",
    "\"2\t1\t1\t2\t1\t1\t1\t1\t1\t1\t3\t4\t4\t3\t5\t3\t4\t3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (\"2  1  0\",\"1  2  3\")\n",
    "reliability_data = [[np.nan if v == '*' else int(v) for v in coder.split()] for coder in data]\n",
    "krippendorff.alpha(reliability_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_RI = (\"2\t1\t1\t1\t1\t1\t1\t1\t1\t3\t2\t4\t4\t3\t3\t4\t3\t5\",\n",
    "\"1\t2\t2\t1\t1\t2\t1\t1\t1\t2\t5\t3\t3\t5\t2\t4\t2\t4\",\n",
    "\"2\t1\t3\t1\t1\t1\t1\t1\t1\t5\t4\t4\t3\t5\t3\t5\t1\t3\",\n",
    "\"2\t1\t1\t1\t1\t2\t1\t1\t2\t4\t2\t5\t5\t4\t4\t5\t3\t5\",\n",
    "\"1\t1\t1\t1\t1\t1\t1\t1\t1\t1\t2\t2\t3\t3\t2\t3\t1\t2\",\n",
    "\"1\t1\t2\t1\t1\t1\t1\t1\t1\t1\t3\t3\t2\t4\t3\t3\t1\t3\",\n",
    "\"1\t2\t3\t1\t1\t2\t2\t1\t2\t3\t3\t4\t4\t4\t3\t5\t2\t5\",\n",
    "\"1\t1\t1\t1\t1\t1\t2\t1\t1\t2\t2\t2\t3\t4\t2\t4\t2\t2\",\n",
    "\"4\t2\t4\t2\t2\t4\t1\t2\t3\t5\t1\t4\t5\t3\t3\t4\t2\t4\",\n",
    "\"2\t1\t2\t1\t1\t2\t1\t1\t2\t2\t4\t3\t3\t3\t3\t4\t2\t4\",\n",
    "\"1\t1\t2\t1\t1\t1\t1\t1\t1\t2\t2\t3\t2\t3\t3\t3\t2\t4\",\n",
    "\"1\t2\t2\t2\t1\t2\t1\t1\t1\t4\t3\t4\t4\t3\t4\t4\t3\t4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_RI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reliability_data_AE = [[np.nan if v == '*' else int(v) for v in coder.split()] for coder in data_AE]\n",
    "reliability_data_EI = [[np.nan if v == '*' else int(v) for v in coder.split()] for coder in data_EI]\n",
    "reliability_data_RI = [[np.nan if v == '*' else int(v) for v in coder.split()] for coder in data_RI]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Alpha AE : \", krippendorff.alpha(reliability_data_AE),\n",
    "\"Alpha EI : \", krippendorff.alpha(reliability_data_EI),\n",
    "\"Alpha RI : \", krippendorff.alpha(reliability_data_RI))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
