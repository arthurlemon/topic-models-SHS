{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook d'entraînement des modèles LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **OBJECTIF GENERAL**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Entraîner les modèle LDA sur les 3 revues**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **OBJECTIFS SPECIFIQUES**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Préparer les matrices document/mot comme input des modèles LDA\n",
    "- Entraîner les modèles LDA avec changement des 3 hyperparamètres : nombre de thèmes - sac de mot/ tf-idf - lemmatisation ou non du vocabulaire \n",
    "- Entraîner 5 modèles avec même configuration pour les 3 revues : étude de fiabilité"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import des bibliothèques et données**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arten\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.models import LdaModel\n",
    "from gensim import models\n",
    "\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports AE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# les 2 premières variables sont issues du notebook Preprocessing_v2\n",
    "\n",
    "# liste de tokens pour chaque article\n",
    "%store -r tokens_bigrams_Corpus_LDA_AE_clean \n",
    "#%store -r tokens_bigrams_Corpus_LDA_AE_clean_lemma \n",
    "\n",
    "# dictionnaire sans lemmatisation\n",
    "%store -r dictionary_AE_2 \n",
    "\n",
    "# dictionnaire avec lemmatisation\n",
    "%store -r dictionary_AE_2_lemma "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports EI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# les 2 premières variables sont issues du notebook Preprocessing_v2\n",
    "\n",
    "# liste de tokens pour chaque article\n",
    "%store -r tokens_bigrams_Corpus_LDA_EI_clean \n",
    "%store -r tokens_bigrams_Corpus_LDA_EI_clean_lemma \n",
    "\n",
    "# dictionnaire sans lemmatisation\n",
    "%store -r dictionary_EI_2 \n",
    "\n",
    "# dictionnaire avec lemmatisation\n",
    "%store -r dictionary_EI_2_lemma "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Imports RI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# les 2 premières variables sont issues du notebook Preprocessing_v2\n",
    "\n",
    "# liste de tokens pour chaque article\n",
    "%store -r tokens_bigrams_Corpus_LDA_RI_clean \n",
    "%store -r tokens_bigrams_Corpus_LDA_RI_clean_lemma \n",
    "\n",
    "# dictionnaire sans lemmatisation\n",
    "%store -r dictionary_RI_2 \n",
    "\n",
    "# dictionnaire avec lemmatisation\n",
    "%store -r dictionary_RI_2_lemma "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **I. Vectorisation du corpus et séparation en train/test**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REVUE AE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_proportion = 0.8 #test_proportion = 1 - train_proportion\n",
    "train_len = int(train_proportion * len(tokens_bigrams_Corpus_LDA_AE_clean))\n",
    "print(\"Taille de l'ensemble d'entraînement: \", train_len, \"articles.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**USAGE : ne créer les corpus qu'une seule fois**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SANS LEMMATISATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(tokens_bigrams_Corpus_LDA_AE_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts_AE = tokens_bigrams_Corpus_LDA_AE_clean[:train_len]\n",
    "test_texts_AE = tokens_bigrams_Corpus_LDA_AE_clean[train_len:]\n",
    "\n",
    "# Création de la matrice Bag-of-words pour le corpus\n",
    "corpus_train_AE = [dictionary_AE_2.doc2bow(doc) for doc in train_texts_AE]\n",
    "corpus_test_AE = [dictionary_AE_2.doc2bow(doc) for doc in test_texts_AE]\n",
    "\n",
    "# Version tf-idf\n",
    "tfidf = models.TfidfModel(corpus_train_AE)\n",
    "corpus_train_AE_tfidf = tfidf[corpus_train_AE]\n",
    "corpus_test_AE_tfidf = tfidf[corpus_test_AE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store train_texts_AE\n",
    "%store test_texts_AE\n",
    "%store corpus_train_AE\n",
    "%store corpus_test_AE\n",
    "%store corpus_train_AE_tfidf\n",
    "%store corpus_test_AE_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AVEC LEMMATISATION**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**REMARQUE** : pas le même shuffle pour les corpus avec et sans lemmatisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(tokens_bigrams_Corpus_LDA_AE_clean_lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts_AE_lemma = tokens_bigrams_Corpus_LDA_AE_clean_lemma[:train_len]\n",
    "test_texts_AE_lemma = tokens_bigrams_Corpus_LDA_AE_clean_lemma[train_len:]\n",
    "\n",
    "# Création de la matrice Bag-of-words pour le corpus\n",
    "corpus_train_AE_lemma = [dictionary_AE_2_lemma.doc2bow(doc) for doc in train_texts_AE_lemma]\n",
    "corpus_test_AE_lemma = [dictionary_AE_2_lemma.doc2bow(doc) for doc in test_texts_AE_lemma]\n",
    "\n",
    "# Version tf-idf\n",
    "tfidf = models.TfidfModel(corpus_train_AE_lemma)\n",
    "corpus_train_AE_tfidf_lemma = tfidf[corpus_train_AE_lemma]\n",
    "corpus_test_AE_tfidf_lemma = tfidf[corpus_test_AE_lemma]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store train_texts_AE_lemma\n",
    "%store test_texts_AE_lemma\n",
    "%store corpus_train_AE_lemma\n",
    "%store corpus_test_AE_lemma\n",
    "%store corpus_train_AE_tfidf_lemma\n",
    "%store corpus_test_AE_tfidf_lemma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REVUE EI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SANS LEMMATISATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(tokens_bigrams_Corpus_LDA_EI_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts_EI = tokens_bigrams_Corpus_LDA_EI_clean[:train_len]\n",
    "test_texts_EI = tokens_bigrams_Corpus_LDA_EI_clean[train_len:]\n",
    "\n",
    "# Création de la matrice Sac de mots pour le corpus\n",
    "corpus_train_EI = [dictionary_EI_2.doc2bow(doc) for doc in train_texts_EI]\n",
    "corpus_test_EI = [dictionary_EI_2.doc2bow(doc) for doc in test_texts_EI]\n",
    "\n",
    "# Version tf-idf\n",
    "tfidf = models.TfidfModel(corpus_train_EI)\n",
    "corpus_train_EI_tfidf = tfidf[corpus_train_EI]\n",
    "corpus_test_EI_tfidf = tfidf[corpus_test_EI]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store train_texts_EI\n",
    "%store test_texts_EI\n",
    "%store corpus_train_EI\n",
    "%store corpus_test_EI\n",
    "%store corpus_train_EI_tfidf\n",
    "%store corpus_test_EI_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AVEC LEMMATISATION**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**REMARQUE** : pas le même shuffle pour les 2 corpus !\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(tokens_bigrams_Corpus_LDA_EI_clean_lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts_EI_lemma = tokens_bigrams_Corpus_LDA_EI_clean_lemma[:train_len]\n",
    "test_texts_EI_lemma = tokens_bigrams_Corpus_LDA_EI_clean_lemma[train_len:]\n",
    "\n",
    "# Création de la matrice Bag-of-words pour le corpus\n",
    "corpus_train_EI_lemma = [dictionary_EI_2_lemma.doc2bow(doc) for doc in train_texts_EI_lemma]\n",
    "corpus_test_EI_lemma = [dictionary_EI_2_lemma.doc2bow(doc) for doc in test_texts_EI_lemma]\n",
    "\n",
    "# Version tf-idf\n",
    "tfidf = models.TfidfModel(corpus_train_EI_lemma)\n",
    "corpus_train_EI_tfidf_lemma = tfidf[corpus_train_EI_lemma]\n",
    "corpus_test_EI_tfidf_lemma = tfidf[corpus_test_EI_lemma]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store train_texts_EI_lemma\n",
    "%store test_texts_EI_lemma\n",
    "%store corpus_train_EI_lemma\n",
    "%store corpus_test_EI_lemma\n",
    "%store corpus_train_EI_tfidf_lemma\n",
    "%store corpus_test_EI_tfidf_lemma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REVUE RI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SANS LEMMATISATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(tokens_bigrams_Corpus_LDA_RI_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts_RI = tokens_bigrams_Corpus_LDA_RI_clean[:train_len]\n",
    "test_texts_RI = tokens_bigrams_Corpus_LDA_RI_clean[train_len:]\n",
    "\n",
    "# Création de la matrice Bag-of-words pour le corpus\n",
    "corpus_train_RI = [dictionary_RI_2.doc2bow(doc) for doc in train_texts_RI]\n",
    "corpus_test_RI = [dictionary_RI_2.doc2bow(doc) for doc in test_texts_RI]\n",
    "\n",
    "# Version tf-idf\n",
    "tfidf = models.TfidfModel(corpus_train_RI)\n",
    "corpus_train_RI_tfidf = tfidf[corpus_train_RI]\n",
    "corpus_test_RI_tfidf = tfidf[corpus_test_RI]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store train_texts_RI\n",
    "%store test_texts_RI\n",
    "%store corpus_train_RI\n",
    "%store corpus_test_RI\n",
    "%store corpus_train_RI_tfidf\n",
    "%store corpus_test_RI_tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AVEC LEMMATISATION**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**REMARQUE** : pas le même shuffle pour les 2 corpus !\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(tokens_bigrams_Corpus_LDA_RI_clean_lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts_RI_lemma = tokens_bigrams_Corpus_LDA_RI_clean_lemma[:train_len]\n",
    "test_texts_RI_lemma = tokens_bigrams_Corpus_LDA_RI_clean_lemma[train_len:]\n",
    "\n",
    "# Création de la matrice Bag-of-words pour le corpus\n",
    "corpus_train_RI_lemma = [dictionary_RI_2_lemma.doc2bow(doc) for doc in train_texts_RI_lemma]\n",
    "corpus_test_RI_lemma = [dictionary_RI_2_lemma.doc2bow(doc) for doc in test_texts_RI_lemma]\n",
    "\n",
    "# Version tf-idf\n",
    "tfidf = models.TfidfModel(corpus_train_RI_lemma)\n",
    "corpus_train_RI_tfidf_lemma = tfidf[corpus_train_RI_lemma]\n",
    "corpus_test_RI_tfidf_lemma = tfidf[corpus_test_RI_lemma]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store train_texts_RI_lemma\n",
    "%store test_texts_RI_lemma\n",
    "%store corpus_train_RI_lemma\n",
    "%store corpus_test_RI_lemma\n",
    "%store corpus_train_RI_tfidf_lemma\n",
    "%store corpus_test_RI_tfidf_lemma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **II. Entraînement du modèle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_LDA(corpus, dictionary, revue = 'AE', alpha = 'auto', num_topic = 5, chunksize=500, passes=20, iterations=400, eval_every=None):\n",
    "    \"\"\" Hyper-paramètres du modèle :\n",
    "    - num_topic = nombre de topics\n",
    "    - chunksize = nombre de documents entraînés chaque itération\n",
    "    passes = nombre d'époques d'entraînement\n",
    "    iterations = nombre de fois qu'on fait converger l'algorithme VB à chaque époque\n",
    "    eval_every = Evaluation de la perplexité pendant entraînement (exigeant)\n",
    "    \"\"\"\n",
    "\n",
    "    temp = dictionary[0]  # This is only to \"load\" the dictionary.\n",
    "    id2word = dictionary.id2token\n",
    "    \n",
    "    return LdaModel(corpus=corpus,id2word=id2word, chunksize=chunksize, \\\n",
    "                       alpha=alpha, eta='auto', \\\n",
    "                       iterations=iterations, num_topics=num_topic, \\\n",
    "                       passes=passes, eval_every=eval_every)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyper-paramètres**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_topics = [x for x in range(1,10)] + [x for x in range(10,110,10)]\n",
    "chunksize=500\n",
    "passes=20\n",
    "iterations=400\n",
    "eval_every= None\n",
    "save = True       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REVUE AE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MODELE SAC DE MOTS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SANS LEMMATISATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r corpus_train_AE\n",
    "dictionary = dictionary_AE_2\n",
    "temp = dictionary[0] \n",
    "id2word = dictionary.id2token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                            | 0/1 [00:00<?, ?it/s]C:\\Users\\arten\\Anaconda3\\lib\\site-packages\\gensim\\models\\ldamodel.py:775: RuntimeWarning: divide by zero encountered in log\n",
      "  diff = np.log(self.expElogbeta)\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 1/1 [09:10<00:00, 550.14s/it]\n"
     ]
    }
   ],
   "source": [
    "for num_topic in tqdm(num_topics):\n",
    "    model = train_model_LDA(corpus=corpus_train_AE, dictionary = dictionary_AE_2, num_topic= num_topic, eval_every = None)\n",
    "    model.save('Résultats_LDA/AE/lda_ae_'+ str(num_topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AVEC LEMMATISATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r corpus_train_AE_lemma\n",
    "dictionary = dictionary_AE_2_lemma\n",
    "temp = dictionary[0] \n",
    "id2word = dictionary.id2token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_topic in tqdm(num_topics):\n",
    "    model = train_model_LDA(corpus=corpus_train_AE_lemma, dictionary = dictionary_AE_2_lemma, num_topic= num_topic, eval_every = None)\n",
    "    model.save('Résultats_LDA/AE/lda_ae_lemma_'+ str(num_topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MODELE TF IDF**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SANS LEMMATISATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r corpus_train_AE\n",
    "dictionary = dictionary_AE_2\n",
    "temp = dictionary[0] \n",
    "id2word = dictionary.id2token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_topic in tqdm(num_topics):\n",
    "    model = train_model_LDA(corpus=corpus_train_AE, dictionary = dictionary_AE_2, num_topic= num_topic, eval_every = None)\n",
    "    model.save('Résultats_LDA/AE/lda_ae_tfidf_'+ str(num_topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AVEC LEMMATISATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r corpus_train_AE_lemma\n",
    "dictionary = dictionary_AE_2_lemma\n",
    "temp = dictionary[0] \n",
    "id2word = dictionary.id2token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_topic in tqdm(num_topics):\n",
    "    model = train_model_LDA(corpus=corpus_train_AE_lemma, dictionary = dictionary_AE_2_lemma, num_topic= num_topic, eval_every = None)\n",
    "    model.save('Résultats_LDA/AE/lda_ae_tfidf_lemma_'+ str(num_topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ETUDE FIABILITE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r corpus_train_AE\n",
    "dictionary = dictionary_AE_2\n",
    "temp = dictionary[0] \n",
    "id2word = dictionary.id2token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [13:11<00:00, 157.89s/it]\n",
      "  0%|                                                                                            | 0/5 [00:00<?, ?it/s]C:\\Users\\arten\\Anaconda3\\lib\\site-packages\\gensim\\models\\ldamodel.py:775: RuntimeWarning: divide by zero encountered in log\n",
      "  diff = np.log(self.expElogbeta)\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████| 5/5 [25:14<00:00, 302.64s/it]\n"
     ]
    }
   ],
   "source": [
    "# Entraîner 5 modèles avec 10 thèmes et 5 modèles à 40 thèmes\n",
    "for num_topic in [10,40]:\n",
    "    for iteration in tqdm(range(5)):\n",
    "        model = train_model_LDA(corpus=corpus_train_AE, dictionary = dictionary_AE_2, num_topic= num_topic, eval_every = None)\n",
    "        #model.save('Résultats_LDA/Fiabilité/lda_ae_'+ str(num_topic) +'_' + str(iteration))\n",
    "        model.save('Résultats_LDA/lda_ae_'+ str(num_topic) +'_' + str(iteration))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REVUE EI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MODELE SAC DE MOTS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SANS LEMMATISATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#récupérer le corpus train\n",
    "%store -r corpus_train_EI\n",
    "dictionary = dictionary_EI_2 # Sans lemmatisation\n",
    "temp = dictionary[0] \n",
    "id2word = dictionary.id2token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 1/1 [10:06<00:00, 606.18s/it]\n"
     ]
    }
   ],
   "source": [
    "for num_topic in tqdm(num_topics):\n",
    "    model = train_model_LDA(corpus=corpus_train_EI, dictionary = dictionary_EI_2, num_topic= num_topic, eval_every = None)\n",
    "    model.save('Résultats_LDA/EI/lda_ei_'+ str(num_topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AVEC LEMMATISATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#récupérer le corpus train\n",
    "%store -r corpus_train_EI_lemma\n",
    "dictionary = dictionary_EI_2_lemma\n",
    "temp = dictionary[0] \n",
    "id2word = dictionary.id2token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_topic in tqdm(num_topics):\n",
    "    model = train_model_LDA(corpus=corpus_train_EI_lemma, dictionary = dictionary_EI_2, num_topic= num_topic, eval_every = None)\n",
    "    model.save('Résultats_LDA/EI/lda_ei_lemma_'+ str(num_topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MODELE TF IDF**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SANS LEMMATISATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#récupérer le corpus train\n",
    "%store -r corpus_train_EI_tfidf\n",
    "dictionary = dictionary_EI_2 # Sans lemmatisation\n",
    "temp = dictionary[0] \n",
    "id2word = dictionary.id2token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_topic in tqdm(num_topics):\n",
    "    model = train_model_LDA(corpus=corpus_train_EI_tfidf, dictionary = dictionary_EI_2, num_topic= num_topic, eval_every = None)\n",
    "    model.save('Résultats_LDA/EI/lda_ei_tfidf'+ str(num_topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AVEC LEMMATISATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#récupérer le corpus train\n",
    "%store -r corpus_train_EI_tfidf_lemma\n",
    "dictionary = dictionary_EI_2_lemma\n",
    "temp = dictionary[0] \n",
    "id2word = dictionary.id2token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_topic in tqdm(num_topics):\n",
    "    model = train_model_LDA(corpus=corpus_train_EI_tfidf_lemma, dictionary = dictionary_EI_2, num_topic= num_topic, eval_every = None)\n",
    "    model.save('Résultats_LDA/EI/lda_ei_tfidf_lemma_'+ str(num_topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ETUDE FIABILITE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraîner 5 modèles avec 10 thèmes et 5 modèles à 40 thèmes\n",
    "for num_topic in [10,40]:\n",
    "    for iteration in tqdm(range(5)):\n",
    "        model = train_model_LDA(corpus=corpus_train_EI, dictionary = dictionary_EI_2, num_topic= num_topic, eval_every = None)\n",
    "        model.save('Résultats_LDA/Fiabilité/lda_ei_'+ str(num_topic) +'_' + str(iteration))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### REVUE RI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SANS LEMMATISATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#récupérer le corpus train\n",
    "%store -r corpus_train_RI\n",
    "dictionary = dictionary_RI_2 # Sans lemmatisation\n",
    "temp = dictionary[0] \n",
    "id2word = dictionary.id2token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 1/1 [09:01<00:00, 541.11s/it]\n"
     ]
    }
   ],
   "source": [
    "for num_topic in tqdm(num_topics):\n",
    "    model = train_model_LDA(corpus=corpus_train_RI, dictionary = dictionary_RI_2, num_topic= num_topic, eval_every = None)\n",
    "    model.save('Résultats_LDA/RI/lda_ri_'+ str(num_topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AVEC LEMMATISATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#récupérer le corpus train\n",
    "%store -r corpus_train_RI_lemma\n",
    "dictionary = dictionary_RI_2_lemma\n",
    "temp = dictionary[0] \n",
    "id2word = dictionary.id2token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for num_topic in tqdm(num_topics):\n",
    "    model = train_model_LDA(corpus=corpus_train_RI_lemma, dictionary = dictionary_RI_2, num_topic= num_topic, eval_every = None)\n",
    "    model.save('Résultats_LDA/RI/lda_ri_lemma_'+ str(num_topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MODELE TF IDF**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SANS LEMMATISATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#récupérer le corpus train\n",
    "%store -r corpus_train_RI_tfidf\n",
    "dictionary = dictionary_RI_2 # Sans lemmatisation\n",
    "temp = dictionary[0] \n",
    "id2word = dictionary.id2token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 9/9 [25:25<00:00, 168.94s/it]\n"
     ]
    }
   ],
   "source": [
    "for num_topic in tqdm(num_topics):\n",
    "    model = train_model_LDA(corpus=corpus_train_RI_tfidf, dictionary = dictionary_RI_2, num_topic= num_topic, eval_every = None)\n",
    "    model.save('Résultats_LDA/RI/lda_ri_tfidf'+ str(num_topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**AVEC LEMMATISATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#récupérer le corpus train\n",
    "%store -r corpus_train_RI_tfidf_lemma\n",
    "dictionary = dictionary_RI_2_lemma\n",
    "temp = dictionary[0] \n",
    "id2word = dictionary.id2token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 3/3 [07:40<00:00, 152.71s/it]\n"
     ]
    }
   ],
   "source": [
    "for num_topic in tqdm(num_topics):\n",
    "    model = train_model_LDA(corpus=corpus_train_RI_tfidf_lemma, dictionary = dictionary_RI_2, num_topic= num_topic, eval_every = None)\n",
    "    model.save('Résultats_LDA/RI/lda_ri_tfidf_lemma'+ str(num_topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ETUDE FIABILITE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraîner 5 modèles avec 10 thèmes et 5 modèles à 40 thèmes\n",
    "for num_topic in [10,40]:\n",
    "    for iteration in tqdm(range(5)):\n",
    "        model = train_model_LDA(corpus=corpus_train_RI, dictionary = dictionary_RI_2, num_topic= num_topic, eval_every = None)\n",
    "        model.save('Résultats_LDA/Fiabilité/lda_ri_'+ str(num_topic) +'_' + str(iteration))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
